# ÐÐ½Ð°Ð»Ð¸Ð· Ð¿Ñ€Ð¾Ð±Ð»ÐµÐ¼ Ð¸Ð· Ð»Ð¾Ð³Ð¾Ð² Ð¸ Ñ‚ÐµÐ»ÐµÐ¼ÐµÑ‚Ñ€Ð¸Ð¸

## ðŸ”´ ÐšÐ Ð˜Ð¢Ð˜Ð§Ð•Ð¡ÐšÐÐ¯ ÐŸÐ ÐžÐ‘Ð›Ð•ÐœÐ: GPU Ð½ÐµÐ´Ð¾ÑÑ‚ÑƒÐ¿ÐµÐ½ ÐºÐ¾Ð½Ñ‚ÐµÐ¹Ð½ÐµÑ€Ñƒ

### ÐŸÑ€Ð¸Ð·Ð½Ð°ÐºÐ¸:
- Ð’ Ð»Ð¾Ð³Ð°Ñ…: `RuntimeError: CUDA driver initialization failed, you might not have a CUDA gpu`
- Ð’ Ð»Ð¾Ð³Ð°Ñ…: `CUDA not available, skipping optimizations`
- ÐÐ° ÑÐºÑ€Ð¸Ð½ÑˆÐ¾Ñ‚Ðµ: RTX 5090 ÐµÑÑ‚ÑŒ, Ð½Ð¾ GPU Ð½Ðµ Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐµÑ‚ÑÑ (0% utilization, P8 ÑÐ¾ÑÑ‚Ð¾ÑÐ½Ð¸Ðµ)

### ÐŸÑ€Ð¸Ñ‡Ð¸Ð½Ñ‹:
1. **ÐžÐ±Ñ€Ð°Ð· Ð½Ðµ Ð¿ÐµÑ€ÐµÑÐ¾Ð±Ñ€Ð°Ð½** - Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐµÑ‚ÑÑ ÑÑ‚Ð°Ñ€Ð°Ñ Ð²ÐµÑ€ÑÐ¸Ñ Ð±ÐµÐ· Ð½Ð°ÑˆÐ¸Ñ… Ð¸ÑÐ¿Ñ€Ð°Ð²Ð»ÐµÐ½Ð¸Ð¹
2. **RunPod Endpoint ÐºÐ¾Ð½Ñ„Ð¸Ð³ÑƒÑ€Ð°Ñ†Ð¸Ñ** - Ð²Ð¾Ð·Ð¼Ð¾Ð¶Ð½Ð¾, Ð½Ðµ Ð½Ð°ÑÑ‚Ñ€Ð¾ÐµÐ½ GPU access Ð¿Ñ€Ð°Ð²Ð¸Ð»ÑŒÐ½Ð¾
3. **ÐšÐ¾Ð½Ñ‚ÐµÐ¹Ð½ÐµÑ€ Ð·Ð°Ð¿ÑƒÑÐºÐ°ÐµÑ‚ÑÑ Ð±ÐµÐ· GPU Ð´Ð¾ÑÑ‚ÑƒÐ¿Ð°** - Ð¿Ñ€Ð¾Ð±Ð»ÐµÐ¼Ð° Ñ RunPod ÐºÐ¾Ð½Ñ‚ÐµÐ¹Ð½ÐµÑ€Ð¾Ð¼

### Ð ÐµÑˆÐµÐ½Ð¸Ðµ:
1. **ÐŸÐµÑ€ÐµÑÐ¾Ð±ÐµÑ€Ð¸Ñ‚Ðµ Ð¾Ð±Ñ€Ð°Ð·** Ñ Ð¿Ð¾ÑÐ»ÐµÐ´Ð½Ð¸Ð¼Ð¸ Ð¸Ð·Ð¼ÐµÐ½ÐµÐ½Ð¸ÑÐ¼Ð¸
2. **ÐŸÑ€Ð¾Ð²ÐµÑ€ÑŒÑ‚Ðµ RunPod Endpoint ÐºÐ¾Ð½Ñ„Ð¸Ð³ÑƒÑ€Ð°Ñ†Ð¸ÑŽ:**
   - GPU Ð´Ð¾Ð»Ð¶ÐµÐ½ Ð±Ñ‹Ñ‚ÑŒ Ð²Ñ‹Ð±Ñ€Ð°Ð½ (RTX 5090)
   - CUDA Ð²ÐµÑ€ÑÐ¸Ñ Ð´Ð¾Ð»Ð¶Ð½Ð° Ð±Ñ‹Ñ‚ÑŒ ÑÐ¾Ð²Ð¼ÐµÑÑ‚Ð¸Ð¼Ð° (12.8+)
   - Endpoint Ð´Ð¾Ð»Ð¶ÐµÐ½ Ð¸Ð¼ÐµÑ‚ÑŒ Ð´Ð¾ÑÑ‚ÑƒÐ¿ Ðº GPU

## âš ï¸ ÐŸÐ ÐžÐ‘Ð›Ð•ÐœÐ: LowVRAM Ð²ÑÐµ ÐµÑ‰Ðµ Ð°ÐºÑ‚Ð¸Ð²ÐµÐ½

### ÐŸÑ€Ð¸Ð·Ð½Ð°ÐºÐ¸:
Ð’ Ð»Ð¾Ð³Ð°Ñ… (ÑÑ‚Ñ€Ð¾ÐºÐ¸ 349-500) Ð²Ð¸Ð´Ð½Ð¾ Ð¼Ð½Ð¾Ð¶ÐµÑÑ‚Ð²Ð¾:
```
lowvram: loaded module regularly decoder.head.0 RMS_norm()
lowvram: loaded module regularly encoder.downsamples.0.residual.0 RMS_norm()
```

### ÐŸÑ€Ð¸Ñ‡Ð¸Ð½Ð°:
ÐÐ²Ñ‚Ð¾Ð¾Ð¿Ñ€ÐµÐ´ÐµÐ»ÐµÐ½Ð¸Ðµ GPU Ð½Ðµ ÑÑ€Ð°Ð±Ð°Ñ‚Ñ‹Ð²Ð°ÐµÑ‚, Ð¿Ð¾Ñ‚Ð¾Ð¼Ñƒ Ñ‡Ñ‚Ð¾:
1. GPU Ð½ÐµÐ´Ð¾ÑÑ‚ÑƒÐ¿ÐµÐ½ (`CUDA not available`)
2. ÐšÐ¾Ð´ Ð² `nodes.py` Ð½Ðµ Ð¿Ñ€Ð¸Ð¼ÐµÐ½ÑÐµÑ‚ÑÑ (Ð¾Ð±Ñ€Ð°Ð· Ð½Ðµ Ð¿ÐµÑ€ÐµÑÐ¾Ð±Ñ€Ð°Ð½)
3. Ð’ workflow Ð½Ðµ Ð´Ð¾Ð±Ð°Ð²Ð»ÐµÐ½ `"load_device": "main_device"`

### Ð ÐµÑˆÐµÐ½Ð¸Ðµ:
1. **ÐŸÐµÑ€ÐµÑÐ¾Ð±ÐµÑ€Ð¸Ñ‚Ðµ Ð¾Ð±Ñ€Ð°Ð·** - Ñ‡Ñ‚Ð¾Ð±Ñ‹ Ð°Ð²Ñ‚Ð¾Ð¾Ð¿Ñ€ÐµÐ´ÐµÐ»ÐµÐ½Ð¸Ðµ GPU Ð·Ð°Ñ€Ð°Ð±Ð¾Ñ‚Ð°Ð»Ð¾
2. **Ð˜ÑÐ¿Ñ€Ð°Ð²ÑŒÑ‚Ðµ Ð´Ð¾ÑÑ‚ÑƒÐ¿ Ðº GPU** - ÑÑ‚Ð¾ Ñ€ÐµÑˆÐ¸Ñ‚ Ð¸ LowVRAM Ð¿Ñ€Ð¾Ð±Ð»ÐµÐ¼Ñƒ
3. **Ð’Ñ€ÐµÐ¼ÐµÐ½Ð½Ð¾ Ð´Ð¾Ð±Ð°Ð²ÑŒÑ‚Ðµ Ð² workflow** `"load_device": "main_device"` Ð´Ð»Ñ Ð½Ð¾Ð´ 41 Ð¸ 42

## âš ï¸ ÐŸÐ Ð•Ð”Ð£ÐŸÐ Ð•Ð–Ð”Ð•ÐÐ˜Ð•: Ð£ÑÑ‚Ð°Ñ€ÐµÐ²ÑˆÐ°Ñ Ð¿ÐµÑ€ÐµÐ¼ÐµÐ½Ð½Ð°Ñ Ð¾ÐºÑ€ÑƒÐ¶ÐµÐ½Ð¸Ñ

### ÐŸÑ€Ð¸Ð·Ð½Ð°ÐºÐ¸:
```
Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead
```

### Ð ÐµÑˆÐµÐ½Ð¸Ðµ:
âœ… **Ð£Ð¶Ðµ Ð¸ÑÐ¿Ñ€Ð°Ð²Ð»ÐµÐ½Ð¾** Ð² Dockerfile Ð¸ `optimize_pytorch.py`
- ÐÑƒÐ¶Ð½Ð¾ Ð¿ÐµÑ€ÐµÑÐ¾Ð±Ñ€Ð°Ñ‚ÑŒ Ð¾Ð±Ñ€Ð°Ð·, Ñ‡Ñ‚Ð¾Ð±Ñ‹ Ð¿Ñ€ÐµÐ´ÑƒÐ¿Ñ€ÐµÐ¶Ð´ÐµÐ½Ð¸Ðµ Ð¸ÑÑ‡ÐµÐ·Ð»Ð¾

## âœ… Ð§Ð¢Ðž Ð ÐÐ‘ÐžÐ¢ÐÐ•Ð¢:

1. **Custom nodes ÑƒÑÑ‚Ð°Ð½Ð°Ð²Ð»Ð¸Ð²Ð°ÑŽÑ‚ÑÑ** - Ð²ÑÐµ Ð·Ð°Ð²Ð¸ÑÐ¸Ð¼Ð¾ÑÑ‚Ð¸ ÑƒÑÑ‚Ð°Ð½Ð¾Ð²Ð»ÐµÐ½Ñ‹ ÑƒÑÐ¿ÐµÑˆÐ½Ð¾
2. **ComfyUI Ð·Ð°Ð¿ÑƒÑÐºÐ°ÐµÑ‚ÑÑ** - ÑÐµÑ€Ð²ÐµÑ€ ÑÑ‚Ð°Ñ€Ñ‚ÑƒÐµÑ‚ (Ñ…Ð¾Ñ‚Ñ Ð½Ðµ Ð¼Ð¾Ð¶ÐµÑ‚ Ð¸Ð½Ð¸Ñ†Ð¸Ð°Ð»Ð¸Ð·Ð¸Ñ€Ð¾Ð²Ð°Ñ‚ÑŒ CUDA)
3. **Workflow Ð²Ñ‹Ð¿Ð¾Ð»Ð½ÑÐµÑ‚ÑÑ** - Ð² Ð»Ð¾Ð³Ð°Ñ… ÐµÑÑ‚ÑŒ ÑƒÑÐ¿ÐµÑˆÐ½Ð¾Ðµ Ð²Ñ‹Ð¿Ð¾Ð»Ð½ÐµÐ½Ð¸Ðµ (job `xe3dimsy9d4om6`)
4. **Video output Ñ€Ð°Ð±Ð¾Ñ‚Ð°ÐµÑ‚** - Ð²Ð¸Ð´ÐµÐ¾ Ñ„Ð°Ð¹Ð»Ñ‹ Ð¾Ð±Ñ€Ð°Ð±Ð°Ñ‚Ñ‹Ð²Ð°ÑŽÑ‚ÑÑ Ð¸ Ð²Ð¾Ð·Ð²Ñ€Ð°Ñ‰Ð°ÑŽÑ‚ÑÑ

## ðŸ“Š ÐÐ½Ð°Ð»Ð¸Ð· Ñ‚ÐµÐ»ÐµÐ¼ÐµÑ‚Ñ€Ð¸Ð¸:

### Ð¡ÐºÑ€Ð¸Ð½ÑˆÐ¾Ñ‚ Ð¿Ð¾ÐºÐ°Ð·Ñ‹Ð²Ð°ÐµÑ‚:
- âœ… RTX 5090 Ñ 34GB VRAM Ð´Ð¾ÑÑ‚ÑƒÐ¿ÐµÐ½
- âœ… CUDA 12.9 ÑƒÑÑ‚Ð°Ð½Ð¾Ð²Ð»ÐµÐ½
- âœ… Driver 575.57.08 Ñ€Ð°Ð±Ð¾Ñ‚Ð°ÐµÑ‚
- âŒ GPU Ð½Ðµ Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐµÑ‚ÑÑ (0% utilization, P8 ÑÐ¾ÑÑ‚Ð¾ÑÐ½Ð¸Ðµ)
- âŒ ÐŸÑ€Ð¾Ñ†ÐµÑÑÐ¾Ð² Ñ‚Ð¾Ð»ÑŒÐºÐ¾ 3 (ComfyUI Ð½Ðµ Ð·Ð°Ð¿ÑƒÑ‰ÐµÐ½ Ð¸Ð»Ð¸ ÑƒÐ¿Ð°Ð»)

### Ð­Ñ‚Ð¾ Ð¾Ð·Ð½Ð°Ñ‡Ð°ÐµÑ‚:
ÐšÐ¾Ð½Ñ‚ÐµÐ¹Ð½ÐµÑ€ Ð½Ðµ Ð¼Ð¾Ð¶ÐµÑ‚ Ð¿Ð¾Ð»ÑƒÑ‡Ð¸Ñ‚ÑŒ Ð´Ð¾ÑÑ‚ÑƒÐ¿ Ðº GPU, Ñ…Ð¾Ñ‚Ñ GPU Ñ„Ð¸Ð·Ð¸Ñ‡ÐµÑÐºÐ¸ Ð¿Ñ€Ð¸ÑÑƒÑ‚ÑÑ‚Ð²ÑƒÐµÑ‚.

## ðŸ› ï¸ Ð”Ð•Ð™Ð¡Ð¢Ð’Ð˜Ð¯ Ð”Ð›Ð¯ Ð˜Ð¡ÐŸÐ ÐÐ’Ð›Ð•ÐÐ˜Ð¯:

### 1. ÐŸÐµÑ€ÐµÑÐ¾Ð±ÐµÑ€Ð¸Ñ‚Ðµ Docker Ð¾Ð±Ñ€Ð°Ð·
```bash
docker build -t your-image-name .
```

### 2. ÐŸÑ€Ð¾Ð²ÐµÑ€ÑŒÑ‚Ðµ ÐºÐ¾Ð½Ñ„Ð¸Ð³ÑƒÑ€Ð°Ñ†Ð¸ÑŽ RunPod Endpoint:
- **GPU**: Ð”Ð¾Ð»Ð¶ÐµÐ½ Ð±Ñ‹Ñ‚ÑŒ Ð²Ñ‹Ð±Ñ€Ð°Ð½ RTX 5090
- **CUDA Version**: 12.8+ (Ð½Ð° ÑÐºÑ€Ð¸Ð½ÑˆÐ¾Ñ‚Ðµ Ð²Ð¸Ð´Ð½Ð¾ 12.9 - Ð¾Ñ‚Ð»Ð¸Ñ‡Ð½Ð¾)
- **Container Image**: Ð£Ð±ÐµÐ´Ð¸Ñ‚ÐµÑÑŒ, Ñ‡Ñ‚Ð¾ Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐµÑ‚ÑÑ Ð¿ÐµÑ€ÐµÑÐ¾Ð±Ñ€Ð°Ð½Ð½Ñ‹Ð¹ Ð¾Ð±Ñ€Ð°Ð·

### 3. ÐŸÐ¾ÑÐ»Ðµ Ð¿ÐµÑ€ÐµÑÐ±Ð¾Ñ€ÐºÐ¸ Ð¿Ñ€Ð¾Ð²ÐµÑ€ÑŒÑ‚Ðµ Ð»Ð¾Ð³Ð¸:
Ð”Ð¾Ð»Ð¶Ð½Ð¾ Ð¿Ð¾ÑÐ²Ð¸Ñ‚ÑŒÑÑ:
```
worker-comfyui: Checking GPU availability
worker-comfyui: GPU detected: NVIDIA RTX 5090 (34GB)
worker-comfyui: CUDA is available via PyTorch
High-end GPU detected: NVIDIA RTX 5090 (34.0GB VRAM). Auto-switching from 'offload_device' to 'main_device'
```

### 4. Ð•ÑÐ»Ð¸ Ð¿Ñ€Ð¾Ð±Ð»ÐµÐ¼Ð° ÑÐ¾Ñ…Ñ€Ð°Ð½ÑÐµÑ‚ÑÑ:
Ð’Ð¾Ð·Ð¼Ð¾Ð¶Ð½Ð¾, Ð¿Ñ€Ð¾Ð±Ð»ÐµÐ¼Ð° Ð² RunPod ÐºÐ¾Ð½Ñ„Ð¸Ð³ÑƒÑ€Ð°Ñ†Ð¸Ð¸ ÐºÐ¾Ð½Ñ‚ÐµÐ¹Ð½ÐµÑ€Ð°. ÐŸÑ€Ð¾Ð²ÐµÑ€ÑŒÑ‚Ðµ:
- Endpoint Template ÐºÐ¾Ð½Ñ„Ð¸Ð³ÑƒÑ€Ð°Ñ†Ð¸ÑŽ
- Container Runtime Ð½Ð°ÑÑ‚Ñ€Ð¾Ð¹ÐºÐ¸
- GPU Sharing Ð½Ð°ÑÑ‚Ñ€Ð¾Ð¹ÐºÐ¸

## ðŸ“ Ð§ÐµÐºÐ»Ð¸ÑÑ‚ Ð¿ÐµÑ€ÐµÐ´ ÑÐ»ÐµÐ´ÑƒÑŽÑ‰Ð¸Ð¼ Ð·Ð°Ð¿ÑƒÑÐºÐ¾Ð¼:

- [ ] ÐžÐ±Ñ€Ð°Ð· Ð¿ÐµÑ€ÐµÑÐ¾Ð±Ñ€Ð°Ð½ Ñ Ð¿Ð¾ÑÐ»ÐµÐ´Ð½Ð¸Ð¼Ð¸ Ð¸Ð·Ð¼ÐµÐ½ÐµÐ½Ð¸ÑÐ¼Ð¸
- [ ] RunPod Endpoint Ð½Ð°ÑÑ‚Ñ€Ð¾ÐµÐ½ Ð½Ð° RTX 5090
- [ ] CUDA Ð²ÐµÑ€ÑÐ¸Ñ ÑÐ¾Ð²Ð¼ÐµÑÑ‚Ð¸Ð¼Ð° (12.8+)
- [ ] Ð’ Ð»Ð¾Ð³Ð°Ñ… Ð²Ð¸Ð´Ð½Ð¾ "GPU detected" Ð¸ "CUDA is available"
- [ ] LowVRAM Ð½Ðµ Ð°ÐºÑ‚Ð¸Ð²ÐµÐ½ (Ð½ÐµÑ‚ `lowvram: loaded module regularly`)
- [ ] GPU utilization > 0% Ð¿Ñ€Ð¸ Ð²Ñ‹Ð¿Ð¾Ð»Ð½ÐµÐ½Ð¸Ð¸ workflow

