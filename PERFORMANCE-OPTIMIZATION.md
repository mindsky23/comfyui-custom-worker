# –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –¥–ª—è RTX 4090

## –ü—Ä–æ–±–ª–µ–º–∞: –ü–æ—á–µ–º—É –æ–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–Ω–∏–º–∞–µ—Ç 20 –º–∏–Ω—É—Ç –≤–º–µ—Å—Ç–æ 90 —Å–µ–∫—É–Ω–¥?

–û—Å–Ω–æ–≤–Ω—ã–µ –ø—Ä–∏—á–∏–Ω—ã –º–µ–¥–ª–µ–Ω–Ω–æ–π —Ä–∞–±–æ—Ç—ã:

1. **LowVRAM —Ä–µ–∂–∏–º** - –º–æ–¥–µ–ª–∏ –∑–∞–≥—Ä—É–∂–∞—é—Ç—Å—è –ø–æ —á–∞—Å—Ç—è–º (`lowvram: loaded module regularly`)
2. **–ö–≤–∞–Ω—Ç–∏–∑–æ–≤–∞–Ω–Ω—ã–µ –º–æ–¥–µ–ª–∏ (GGUF/Q5_K)** - –º–µ–¥–ª–µ–Ω–Ω–µ–µ –ø–æ–ª–Ω—ã—Ö FP16 –º–æ–¥–µ–ª–µ–π
3. **–û—Ç—Å—É—Ç—Å—Ç–≤–∏–µ TF32 –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏** - RTX 4090 –º–æ–∂–µ—Ç —Ä–∞–±–æ—Ç–∞—Ç—å –≤ 2-3 —Ä–∞–∑–∞ –±—ã—Å—Ç—Ä–µ–µ
4. **cuDNN –Ω–µ –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω** - –∞–ª–≥–æ—Ä–∏—Ç–º—ã –Ω–µ –ø–æ–¥–±–∏—Ä–∞—é—Ç—Å—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏

## ‚úÖ –ß—Ç–æ —É–∂–µ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–æ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏:

1. **TF32 (TensorFloat-32) –≤–∫–ª—é—á–µ–Ω** - —É—Å–∫–æ—Ä–µ–Ω–∏–µ 2-3x –¥–ª—è RTX 4090
2. **cuDNN benchmark –≤–∫–ª—é—á–µ–Ω** - –∞–≤—Ç–æ–ø–æ–¥–±–æ—Ä –±—ã—Å—Ç—Ä—ã—Ö –∞–ª–≥–æ—Ä–∏—Ç–º–æ–≤
3. **–û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –ø–∞–º—è—Ç–∏ CUDA** - `max_split_size_mb:512` –¥–ª—è RTX 4090
4. **Async CUDA execution** - –Ω–µ–±–ª–æ–∫–∏—Ä—É—é—â–∏–µ –æ–ø–µ—Ä–∞—Ü–∏–∏

## üéØ –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ (–≤—Ä—É—á–Ω—É—é):

### 1. –û—Ç–∫–ª—é—á–∏—Ç–µ LowVRAM —Ä–µ–∂–∏–º –≤ workflow

**–ü—Ä–æ–±–ª–µ–º–∞:** –í –ª–æ–≥–∞—Ö –≤–∏–¥–Ω–æ `lowvram: loaded module regularly` - —ç—Ç–æ –æ–∑–Ω–∞—á–∞–µ—Ç, —á—Ç–æ –º–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–∞–µ—Ç—Å—è –ø–æ —á–∞—Å—Ç—è–º, —á—Ç–æ –æ—á–µ–Ω—å –º–µ–¥–ª–µ–Ω–Ω–æ.

**–†–µ—à–µ–Ω–∏–µ:**
- –í ComfyUI workflow **–ù–ï –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ** –Ω–æ–¥—ã —Å "LowVRAM" –≤ –Ω–∞–∑–≤–∞–Ω–∏–∏
- –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ –æ–±—ã—á–Ω—ã–µ –Ω–æ–¥—ã –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–µ–π (–±–µ–∑ LowVRAM)
- RTX 4090 –∏–º–µ–µ—Ç 24GB VRAM - —ç—Ç–æ–≥–æ –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–ª—è –ø–æ–ª–Ω–æ–π –∑–∞–≥—Ä—É–∑–∫–∏ –±–æ–ª—å—à–∏–Ω—Å—Ç–≤–∞ –º–æ–¥–µ–ª–µ–π

**–ü—Ä–∏–º–µ—Ä (–ø–ª–æ—Ö–æ):**
- ‚ùå `Unet Loader (GGUF) - Low VRAM`
- ‚ùå `Model Loader - LowVRAM`

**–ü—Ä–∏–º–µ—Ä (—Ö–æ—Ä–æ—à–æ):**
- ‚úÖ `Unet Loader (GGUF)` - –æ–±—ã—á–Ω–∞—è –≤–µ—Ä—Å–∏—è
- ‚úÖ `Model Loader` - –æ–±—ã—á–Ω–∞—è –≤–µ—Ä—Å–∏—è

### 2. –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ –ø–æ–ª–Ω—ã–µ –º–æ–¥–µ–ª–∏ –≤–º–µ—Å—Ç–æ –∫–≤–∞–Ω—Ç–∏–∑–æ–≤–∞–Ω–Ω—ã—Ö

**–ü—Ä–æ–±–ª–µ–º–∞:** GGUF/Q5_K –∫–≤–∞–Ω—Ç–∏–∑–∞—Ü–∏—è —ç–∫–æ–Ω–æ–º–∏—Ç –ø–∞–º—è—Ç—å, –Ω–æ –∑–∞–º–µ–¥–ª—è–µ—Ç –∏–Ω—Ñ–µ—Ä–µ–Ω—Å.

**–†–µ—à–µ–Ω–∏–µ:**
- –ï—Å–ª–∏ –ø–æ–∑–≤–æ–ª—è–µ—Ç VRAM (24GB –Ω–∞ RTX 4090), –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ FP16 –∏–ª–∏ FP8 –º–æ–¥–µ–ª–∏ –≤–º–µ—Å—Ç–æ GGUF/Q5_K
- –î–ª—è WAN 2.2: –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ `Wan2.2-I2V-A14B-FP8` –≤–º–µ—Å—Ç–æ `Wan2.2-I2V-A14B-LowNoise-Q5_K_S.gguf`

**–ü—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–∞:**
- –ë—ã—Å—Ç—Ä–µ–µ –∏–Ω—Ñ–µ—Ä–µ–Ω—Å (2-3x)
- –ú–µ–Ω—å—à–µ –∑–∞–¥–µ—Ä–∂–µ–∫ –Ω–∞ –∑–∞–≥—Ä—É–∑–∫—É –º–æ–¥—É–ª–µ–π
- –ë–æ–ª–µ–µ —Ç–æ—á–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã

### 3. –ù–∞—Å—Ç—Ä–æ–π—Ç–µ workflow –¥–ª—è –≤—ã—Å–æ–∫–æ–ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ–≥–æ —Ä–µ–∂–∏–º–∞

**–†–µ–∫–æ–º–µ–Ω–¥—É–µ–º—ã–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –¥–ª—è RTX 4090:**

```
- Precision: FP16 –∏–ª–∏ FP8 (–Ω–µ FP32)
- Batch Size: –£–≤–µ–ª–∏—á—å—Ç–µ –¥–æ –º–∞–∫—Å–∏–º—É–º–∞ (–µ—Å–ª–∏ –ø–æ–∑–≤–æ–ª—è–µ—Ç VRAM)
- Model Loading: –ü–æ–ª–Ω–∞—è –∑–∞–≥—Ä—É–∑–∫–∞ –≤ VRAM (–Ω–µ offload_device)
- LowVRAM Mode: –û–¢–ö–õ–Æ–ß–ï–ù
```

### 4. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ, —á—Ç–æ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ –ø—Ä–∏–º–µ–Ω–µ–Ω—ã

–ü–æ—Å–ª–µ –ø–µ—Ä–µ—Å–±–æ—Ä–∫–∏ –æ–±—Ä–∞–∑–∞, –≤ –ª–æ–≥–∞—Ö –¥–æ–ª–∂–Ω–æ –±—ã—Ç—å:

```
worker-comfyui: Applying PyTorch performance optimizations for RTX 4090
GPU detected: NVIDIA GeForce RTX 4090 (24.0GB VRAM)
‚úì Enabled TF32 (TensorFloat-32) for faster inference
‚úì Enabled cuDNN benchmark and non-deterministic algorithms
‚úì Set CUDA memory allocation: max_split_size_mb=512
‚úì Disabled CUDA blocking for async execution
‚úì Cleared GPU cache
```

## üìä –û–∂–∏–¥–∞–µ–º–æ–µ —É–ª—É—á—à–µ–Ω–∏–µ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏:

–ü–æ—Å–ª–µ –ø—Ä–∏–º–µ–Ω–µ–Ω–∏—è –≤—Å–µ—Ö –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–π:

- **–ë—ã–ª–æ:** 20 –º–∏–Ω—É—Ç
- **–°—Ç–∞–Ω–µ—Ç:** 2-4 –º–∏–Ω—É—Ç—ã (–ø—Ä–∏ —É—Å–ª–æ–≤–∏–∏ –æ—Ç–∫–ª—é—á–µ–Ω–∏—è LowVRAM)
- **–£—Å–∫–æ—Ä–µ–Ω–∏–µ:** 5-10x

## üîß –ö–∞–∫ –ø—Ä–æ–≤–µ—Ä–∏—Ç—å —Ç–µ–∫—É—â–∏–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏:

–í –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–µ –≤—ã–ø–æ–ª–Ω–∏—Ç–µ:

```bash
python -c "import torch; print(f'TF32: {torch.backends.cuda.matmul.allow_tf32}'); print(f'cuDNN Benchmark: {torch.backends.cudnn.benchmark}')"
```

–î–æ–ª–∂–Ω–æ –≤—ã–≤–µ—Å—Ç–∏:
```
TF32: True
cuDNN Benchmark: True
```

## ‚ö†Ô∏è –í–∞–∂–Ω–æ:

1. **LowVRAM —Ä–µ–∂–∏–º** - —ç—Ç–æ –≥–ª–∞–≤–Ω—ã–π —É–±–∏–π—Ü–∞ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –¥–ª—è RTX 4090
2. **GGUF –∫–≤–∞–Ω—Ç–∏–∑–∞—Ü–∏—è** - —ç–∫–æ–Ω–æ–º–∏—Ç –ø–∞–º—è—Ç—å, –Ω–æ –∑–∞–º–µ–¥–ª—è–µ—Ç —Ä–∞–±–æ—Ç—É
3. **TF32** - —Ä–∞–±–æ—Ç–∞–µ—Ç —Ç–æ–ª—å–∫–æ –Ω–∞ RTX 30xx/40xx (Ada Lovelace, Ampere)
4. **–û–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ –ø—Ä–∏–º–µ–Ω—è—é—Ç—Å—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏** –ø—Ä–∏ —Å—Ç–∞—Ä—Ç–µ –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–∞

## üêõ –ï—Å–ª–∏ –≤—Å–µ –µ—â–µ –º–µ–¥–ª–µ–Ω–Ω–æ:

1. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –ª–æ–≥–∏ –Ω–∞ –Ω–∞–ª–∏—á–∏–µ `lowvram: loaded module regularly`
2. –ï—Å–ª–∏ –≤–∏–¥–∏—Ç–µ —ç—Ç–æ - –æ—Ç–∫–ª—é—á–∏—Ç–µ LowVRAM –≤ workflow
3. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ, —á—Ç–æ –º–æ–¥–µ–ª—å –Ω–µ –∫–≤–∞–Ω—Ç–∏–∑–æ–≤–∞–Ω–∞ (GGUF/Q5_K)
4. –£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ –º–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–∞–µ—Ç—Å—è –ø–æ–ª–Ω–æ—Å—Ç—å—é –≤ VRAM

---

**–ü—Ä–∏–º–µ—á–∞–Ω–∏–µ:** –ù–∞ RTX 4090 (24GB VRAM) –Ω–µ—Ç –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å LowVRAM —Ä–µ–∂–∏–º –¥–ª—è –±–æ–ª—å—à–∏–Ω—Å—Ç–≤–∞ –º–æ–¥–µ–ª–µ–π. –ü–æ–ª–Ω–∞—è –∑–∞–≥—Ä—É–∑–∫–∞ –≤ VRAM –∑–Ω–∞—á–∏—Ç–µ–ª—å–Ω–æ –±—ã—Å—Ç—Ä–µ–µ.

