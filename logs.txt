2025-10-31  18:16:23.078 | info | ezqzk1cgnlxfc8 | Finished.
2025-10-31  18:16:23.078 | info | ezqzk1cgnlxfc8 | worker-comfyui - Job failed with no output images.\n
2025-10-31  18:16:23.078 | info | ezqzk1cgnlxfc8 | worker-comfyui - Job completed with errors/warnings: ["Workflow execution error: Node Type: KSamplerAdvanced, Node ID: 6, Message: Command '['/usr/bin/gcc', '/tmp/latentsync_4ca5f8c4/tmpjofwt5tp/cuda_utils.c', '-O3', '-shared', '-fPIC', '-Wno-psabi', '-o', '/tmp/latentsync_4ca5f8c4/tmpjofwt5tp/cuda_utils.cpython-312-x86_64-linux-gnu.so', '-lcuda', '-L/opt/venv/lib/python3.12/site-packages/triton/backends/nvidia/lib', '-L/usr/lib/x86_64-linux-gnu', '-I/opt/venv/lib/python3.12/site-packages/triton/backends/nvidia/include', '-I/tmp/latentsync_4ca5f8c4/tmpjofwt5tp', '-I/usr/include/python3.12']' returned non-zero exit status 1.\n"]\n
2025-10-31  18:16:23.078 | info | ezqzk1cgnlxfc8 | worker-comfyui - Closing websocket connection.\n
2025-10-31  18:16:23.078 | info | ezqzk1cgnlxfc8 | worker-comfyui - Processing 0 output nodes...\n
2025-10-31  18:16:22.830 | info | ezqzk1cgnlxfc8 | worker-comfyui - No outputs found in history for prompt 65ebb5a2-61b2-429b-9fd5-c526091c9de9.\n
2025-10-31  18:16:22.830 | info | ezqzk1cgnlxfc8 | worker-comfyui - Fetching history for prompt 65ebb5a2-61b2-429b-9fd5-c526091c9de9...\n
2025-10-31  18:16:22.830 | info | ezqzk1cgnlxfc8 | \n
2025-10-31  18:16:22.182 | info | ezqzk1cgnlxfc8 | worker-comfyui - Execution error received: Node Type: KSamplerAdvanced, Node ID: 6, Message: Command '['/usr/bin/gcc', '/tmp/latentsync_4ca5f8c4/tmpjofwt5tp/cuda_utils.c', '-O3', '-shared', '-fPIC', '-Wno-psabi', '-o', '/tmp/latentsync_4ca5f8c4/tmpjofwt5tp/cuda_utils.cpython-312-x86_64-linux-gnu.so', '-lcuda', '-L/opt/venv/lib/python3.12/site-packages/triton/backends/nvidia/lib', '-L/usr/lib/x86_64-linux-gnu', '-I/opt/venv/lib/python3.12/site-packages/triton/backends/nvidia/include', '-I/tmp/latentsync_4ca5f8c4/tmpjofwt5tp', '-I/usr/include/python3.12']' returned non-zero exit status 1.\n
2025-10-31  18:16:22.182 | info | ezqzk1cgnlxfc8 | Prompt executed in 133.96 seconds\n
2025-10-31  18:16:22.182 | info | ezqzk1cgnlxfc8 | \n
2025-10-31  18:16:22.182 | info | ezqzk1cgnlxfc8 | subprocess.CalledProcessError: Command '['/usr/bin/gcc', '/tmp/latentsync_4ca5f8c4/tmpjofwt5tp/cuda_utils.c', '-O3', '-shared', '-fPIC', '-Wno-psabi', '-o', '/tmp/latentsync_4ca5f8c4/tmpjofwt5tp/cuda_utils.cpython-312-x86_64-linux-gnu.so', '-lcuda', '-L/opt/venv/lib/python3.12/site-packages/triton/backends/nvidia/lib', '-L/usr/lib/x86_64-linux-gnu', '-I/opt/venv/lib/python3.12/site-packages/triton/backends/nvidia/include', '-I/tmp/latentsync_4ca5f8c4/tmpjofwt5tp', '-I/usr/include/python3.12']' returned non-zero exit status 1.\n
2025-10-31  18:16:22.182 | info | ezqzk1cgnlxfc8 |     raise CalledProcessError(retcode, cmd)\n
2025-10-31  18:16:22.182 | info | ezqzk1cgnlxfc8 |   File "/usr/lib/python3.12/subprocess.py", line 413, in check_call\n
2025-10-31  18:16:22.182 | info | ezqzk1cgnlxfc8 |     subprocess.check_call(cc_cmd, stdout=subprocess.DEVNULL)\n
2025-10-31  18:16:22.182 | info | ezqzk1cgnlxfc8 |   File "/opt/venv/lib/python3.12/site-packages/triton/runtime/build.py", line 51, in _build\n
2025-10-31  18:16:22.182 | info | ezqzk1cgnlxfc8 |          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n
2025-10-31  18:16:22.182 | info | ezqzk1cgnlxfc8 |     so = _build(name, src_path, tmpdir, library_dirs or [], include_dirs or [], libraries or [], ccflags or [])\n
2025-10-31  18:16:22.182 | info | ezqzk1cgnlxfc8 |   File "/opt/venv/lib/python3.12/site-packages/triton/runtime/build.py", line 89, in compile_module_from_src\n
2025-10-31  18:16:22.182 | info | ezqzk1cgnlxfc8 |           ^^^^^^^^^^^^^^^^^^^^^^^^\n
2025-10-31  18:16:22.182 | info | ezqzk1cgnlxfc8 |     mod = compile_module_from_src(\n
2025-10-31  18:16:22.182 | info | ezqzk1cgnlxfc8 |   File "/opt/venv/lib/python3.12/site-packages/triton/backends/nvidia/driver.py", line 63, in __init__\n
2025-10-31  18:16:22.182 | info | ezqzk1cgnlxfc8 |                  ^^^^^^^^^^^\n
2025-10-31  18:16:22.182 | info | ezqzk1cgnlxfc8 |     self.utils = CudaUtils()  # TODO: make static\n
2025-10-31  18:16:22.182 | info | ezqzk1cgnlxfc8 |   File "/opt/venv/lib/python3.12/site-packages/triton/backends/nvidia/driver.py", line 719, in __init__\n
2025-10-31  18:16:22.182 | info | ezqzk1cgnlxfc8 |            ^^^^^^^^^^^^^^^^^^^\n
2025-10-31  18:16:22.182 | info | ezqzk1cgnlxfc8 |     return active_drivers[0]()\n
2025-10-31  18:16:22.182 | info | ezqzk1cgnlxfc8 |   File "/opt/venv/lib/python3.12/site-packages/triton/runtime/driver.py", line 10, in _create_driver\n
2025-10-31  18:16:22.182 | info | ezqzk1cgnlxfc8 |                     ^^^^^^^^^^^^^^^^\n
2025-10-31  18:16:22.182 | info | ezqzk1cgnlxfc8 |     self._default = _create_driver()\n
2025-10-31  18:16:22.182 | info | ezqzk1cgnlxfc8 |   File "/opt/venv/lib/python3.12/site-packages/triton/runtime/driver.py", line 22, in default\n
2025-10-31  18:16:22.182 | info | ezqzk1cgnlxfc8 |                    ^^^^^^^^^^^^\n
2025-10-31  18:16:22.182 | info | ezqzk1cgnlxfc8 |     self._active = self.default\n
2025-10-31  18:16:22.182 | info | ezqzk1cgnlxfc8 |   File "/opt/venv/lib/python3.12/site-packages/triton/runtime/driver.py", line 28, in active\n
2025-10-31  18:16:22.181 | info | ezqzk1cgnlxfc8 |              ^^^^^^^^^^^^^\n
2025-10-31  18:16:22.181 | info | ezqzk1cgnlxfc8 |     device = driver.active.get_current_device()\n
2025-10-31  18:16:22.181 | info | ezqzk1cgnlxfc8 |   File "/opt/venv/lib/python3.12/site-packages/triton/runtime/jit.py", line 713, in run\n
2025-10-31  18:16:22.181 | info | ezqzk1cgnlxfc8 |                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n
2025-10-31  18:16:22.181 | info | ezqzk1cgnlxfc8 |     return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)\n
2025-10-31  18:16:22.181 | info | ezqzk1cgnlxfc8 |   File "/opt/venv/lib/python3.12/site-packages/triton/runtime/jit.py", line 419, in <lambda>\n
2025-10-31  18:16:22.181 | info | ezqzk1cgnlxfc8 |     quant_per_block_int8_kernel[grid](\n
2025-10-31  18:16:22.181 | info | ezqzk1cgnlxfc8 |   File "/opt/venv/lib/python3.12/site-packages/sageattention/quant_per_block.py", line 63, in per_block_int8\n
2025-10-31  18:16:22.181 | info | ezqzk1cgnlxfc8 |                                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n
2025-10-31  18:16:22.181 | info | ezqzk1cgnlxfc8 |     q_int8, q_scale, k_int8, k_scale = per_block_int8(q, k, sm_scale=sm_scale, tensor_layout=tensor_layout)\n
2025-10-31  18:16:22.181 | info | ezqzk1cgnlxfc8 |   File "/opt/venv/lib/python3.12/site-packages/sageattention/core.py", line 105, in sageattn\n
2025-10-31  18:16:22.181 | info | ezqzk1cgnlxfc8 |            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n
2025-10-31  18:16:22.181 | info | ezqzk1cgnlxfc8 |     return sageattn(q, k, v, is_causal=is_causal, attn_mask=attn_mask, tensor_layout=tensor_layout)\n
2025-10-31  18:16:22.181 | info | ezqzk1cgnlxfc8 |   File "/comfyui/custom_nodes/ComfyUI-KJNodes/nodes/model_optimization_nodes.py", line 99, in func\n
2025-10-31  18:16:22.181 | info | ezqzk1cgnlxfc8 |           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n
2025-10-31  18:16:22.181 | info | ezqzk1cgnlxfc8 |     out = sage_func(q, k, v, attn_mask=mask, is_causal=False, tensor_layout=tensor_layout)\n
2025-10-31  18:16:22.181 | info | ezqzk1cgnlxfc8 |   File "/comfyui/custom_nodes/ComfyUI-KJNodes/nodes/model_optimization_nodes.py", line 153, in attention_sage\n
2025-10-31  18:16:22.181 | info | ezqzk1cgnlxfc8 |            ^^^^^^^^^^^^^^^^^^^\n
2025-10-31  18:16:22.181 | info | ezqzk1cgnlxfc8 |     return fn(*args, **kwargs)\n
2025-10-31  18:16:22.181 | info | ezqzk1cgnlxfc8 |   File "/opt/venv/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py", line 1044, in _fn\n
2025-10-31  18:16:22.181 | info | ezqzk1cgnlxfc8 |         ^^^^^^^^^^^^^^^^^^^^\n
2025-10-31  18:16:22.181 | info | ezqzk1cgnlxfc8 |     x = optimized_attention(\n
2025-10-31  18:16:22.181 | info | ezqzk1cgnlxfc8 |   File "/comfyui/comfy/ldm/wan/model.py", line 81, in forward\n
2025-10-31  18:16:22.181 | info | ezqzk1cgnlxfc8 |            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n
2025-10-31  18:16:22.181 | info | ezqzk1cgnlxfc8 |     return forward_call(*args, **kwargs)\n
2025-10-31  18:16:22.181 | info | ezqzk1cgnlxfc8 |   File "/opt/venv/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl\n
2025-10-31  18:16:22.181 | info | ezqzk1cgnlxfc8 |            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n
2025-10-31  18:16:22.181 | info | ezqzk1cgnlxfc8 |     return self._call_impl(*args, **kwargs)\n
2025-10-31  18:16:22.181 | info | ezqzk1cgnlxfc8 |   File "/opt/venv/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl\n
2025-10-31  18:16:22.181 | info | ezqzk1cgnlxfc8 |         ^^^^^^^^^^^^^^^\n
2025-10-31  18:16:22.181 | info | ezqzk1cgnlxfc8 |     y = self.self_attn(\n
2025-10-31  18:16:22.181 | info | ezqzk1cgnlxfc8 |   File "/comfyui/comfy/ldm/wan/model.py", line 235, in forward\n
2025-10-31  18:16:22.181 | info | ezqzk1cgnlxfc8 |            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n
2025-10-31  18:16:22.180 | info | ezqzk1cgnlxfc8 |     return forward_call(*args, **kwargs)\n
2025-10-31  18:16:22.180 | info | ezqzk1cgnlxfc8 |   File "/opt/venv/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl\n
2025-10-31  18:16:22.180 | info | ezqzk1cgnlxfc8 |            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n
2025-10-31  18:16:22.180 | info | ezqzk1cgnlxfc8 |     return self._call_impl(*args, **kwargs)\n
2025-10-31  18:16:22.180 | info | ezqzk1cgnlxfc8 |   File "/opt/venv/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl\n
2025-10-31  18:16:22.180 | info | ezqzk1cgnlxfc8 |         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n
2025-10-31  18:16:22.180 | info | ezqzk1cgnlxfc8 |     x = block(x, e=e0, freqs=freqs, context=context, context_img_len=context_img_len, transformer_options=transformer_options)\n
2025-10-31  18:16:22.180 | info | ezqzk1cgnlxfc8 |   File "/comfyui/comfy/ldm/wan/model.py", line 579, in forward_orig\n
2025-10-31  18:16:22.180 | info | ezqzk1cgnlxfc8 |            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n
2025-10-31  18:16:22.180 | info | ezqzk1cgnlxfc8 |     return self.forward_orig(x, timestep, context, clip_fea=clip_fea, freqs=freqs, transformer_options=transformer_options, **kwargs)[:, :, :t, :h, :w]\n
2025-10-31  18:16:22.180 | info | ezqzk1cgnlxfc8 |   File "/comfyui/comfy/ldm/wan/model.py", line 634, in _forward\n
2025-10-31  18:16:22.180 | info | ezqzk1cgnlxfc8 |            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n
2025-10-31  18:16:22.180 | info | ezqzk1cgnlxfc8 |     return self.original(*args, **kwargs)\n
2025-10-31  18:16:22.180 | info | ezqzk1cgnlxfc8 |   File "/comfyui/comfy/patcher_extension.py", line 112, in execute\n
2025-10-31  18:16:22.180 | info | ezqzk1cgnlxfc8 |            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n
2025-10-31  18:16:22.180 | info | ezqzk1cgnlxfc8 |     return comfy.patcher_extension.WrapperExecutor.new_class_executor(\n
2025-10-31  18:16:22.180 | info | ezqzk1cgnlxfc8 |   File "/comfyui/comfy/ldm/wan/model.py", line 614, in forward\n
2025-10-31  18:16:22.180 | info | ezqzk1cgnlxfc8 |            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n
2025-10-31  18:16:22.180 | info | ezqzk1cgnlxfc8 |     return forward_call(*args, **kwargs)\n
2025-10-31  18:16:22.180 | info | ezqzk1cgnlxfc8 |   File "/opt/venv/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl\n
2025-10-31  18:16:22.180 | info | ezqzk1cgnlxfc8 |            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n
2025-10-31  18:16:22.180 | info | ezqzk1cgnlxfc8 |     return self._call_impl(*args, **kwargs)\n
2025-10-31  18:16:22.180 | info | ezqzk1cgnlxfc8 |   File "/opt/venv/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl\n
2025-10-31  18:16:22.180 | info | ezqzk1cgnlxfc8 |                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n
2025-10-31  18:16:22.180 | info | ezqzk1cgnlxfc8 |     model_output = self.diffusion_model(xc, t, context=context, control=control, transformer_options=transformer_options, **extra_conds).float()\n
2025-10-31  18:16:22.180 | info | ezqzk1cgnlxfc8 |   File "/comfyui/comfy/model_base.py", line 200, in _apply_model\n
2025-10-31  18:16:22.180 | info | ezqzk1cgnlxfc8 |            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n
2025-10-31  18:16:22.180 | info | ezqzk1cgnlxfc8 |     return self.original(*args, **kwargs)\n
2025-10-31  18:16:22.180 | info | ezqzk1cgnlxfc8 |   File "/comfyui/comfy/patcher_extension.py", line 112, in execute\n
2025-10-31  18:16:22.180 | info | ezqzk1cgnlxfc8 |            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n
2025-10-31  18:16:22.180 | info | ezqzk1cgnlxfc8 |     return comfy.patcher_extension.WrapperExecutor.new_class_executor(\n
2025-10-31  18:16:22.180 | info | ezqzk1cgnlxfc8 |   File "/comfyui/comfy/model_base.py", line 161, in apply_model\n
2025-10-31  18:16:22.180 | info | ezqzk1cgnlxfc8 |              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n
2025-10-31  18:16:22.179 | info | ezqzk1cgnlxfc8 |     output = model.apply_model(input_x, timestep_, **c).chunk(batch_chunks)\n
2025-10-31  18:16:22.179 | info | ezqzk1cgnlxfc8 |   File "/comfyui/comfy/samplers.py", line 326, in _calc_cond_batch\n
2025-10-31  18:16:22.179 | info | ezqzk1cgnlxfc8 |            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n
2025-10-31  18:16:22.179 | info | ezqzk1cgnlxfc8 |     return self.original(*args, **kwargs)\n
2025-10-31  18:16:22.179 | info | ezqzk1cgnlxfc8 |   File "/comfyui/comfy/patcher_extension.py", line 112, in execute\n
2025-10-31  18:16:22.179 | info | ezqzk1cgnlxfc8 |            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n
2025-10-31  18:16:22.179 | info | ezqzk1cgnlxfc8 |     return executor.execute(model, conds, x_in, timestep, model_options)\n
2025-10-31  18:16:22.179 | info | ezqzk1cgnlxfc8 |   File "/comfyui/comfy/samplers.py", line 214, in _calc_cond_batch_outer\n
2025-10-31  18:16:22.179 | info | ezqzk1cgnlxfc8 |            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n
2025-10-31  18:16:22.179 | info | ezqzk1cgnlxfc8 |     return _calc_cond_batch_outer(model, conds, x_in, timestep, model_options)\n
2025-10-31  18:16:22.179 | info | ezqzk1cgnlxfc8 |   File "/comfyui/comfy/samplers.py", line 206, in calc_cond_batch\n
2025-10-31  18:16:22.179 | info | ezqzk1cgnlxfc8 |           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n
2025-10-31  18:16:22.179 | info | ezqzk1cgnlxfc8 |     out = calc_cond_batch(model, conds, x, timestep, model_options)\n
2025-10-31  18:16:22.179 | info | ezqzk1cgnlxfc8 |   File "/comfyui/comfy/samplers.py", line 381, in sampling_function\n
2025-10-31  18:16:22.179 | info | ezqzk1cgnlxfc8 |            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n
2025-10-31  18:16:22.179 | info | ezqzk1cgnlxfc8 |     return sampling_function(self.inner_model, x, timestep, self.conds.get("negative", None), self.conds.get("positive", None), self.cfg, model_options=model_options, seed=seed)\n
2025-10-31  18:16:22.179 | info | ezqzk1cgnlxfc8 |   File "/comfyui/comfy/samplers.py", line 963, in predict_noise\n
2025-10-31  18:16:22.179 | info | ezqzk1cgnlxfc8 |            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n
2025-10-31  18:16:22.179 | info | ezqzk1cgnlxfc8 |     return self.original(*args, **kwargs)\n
2025-10-31  18:16:22.179 | info | ezqzk1cgnlxfc8 |   File "/comfyui/comfy/patcher_extension.py", line 112, in execute\n
2025-10-31  18:16:22.179 | info | ezqzk1cgnlxfc8 |       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n
2025-10-31  18:16:22.179 | info | ezqzk1cgnlxfc8 |     ).execute(x, timestep, model_options, seed)\n
2025-10-31  18:16:22.179 | info | ezqzk1cgnlxfc8 |   File "/comfyui/comfy/samplers.py", line 960, in outer_predict_noise\n
2025-10-31  18:16:22.179 | info | ezqzk1cgnlxfc8 |            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n
2025-10-31  18:16:22.179 | info | ezqzk1cgnlxfc8 |     return self.outer_predict_noise(*args, **kwargs)\n
2025-10-31  18:16:22.179 | info | ezqzk1cgnlxfc8 |   File "/comfyui/comfy/samplers.py", line 953, in __call__\n
2025-10-31  18:16:22.179 | info | ezqzk1cgnlxfc8 |           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n
2025-10-31  18:16:22.179 | info | ezqzk1cgnlxfc8 |     out = self.inner_model(x, sigma, model_options=model_options, seed=seed)\n
2025-10-31  18:16:22.179 | info | ezqzk1cgnlxfc8 |   File "/comfyui/comfy/samplers.py", line 401, in __call__\n
2025-10-31  18:16:22.179 | info | ezqzk1cgnlxfc8 |                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n
2025-10-31  18:16:22.179 | info | ezqzk1cgnlxfc8 |     denoised = model(x, sigmas[i] * s_in, **extra_args)\n
2025-10-31  18:16:22.179 | info | ezqzk1cgnlxfc8 |   File "/comfyui/comfy/k_diffusion/sampling.py", line 1009, in sample_lcm\n
2025-10-31  18:16:22.179 | info | ezqzk1cgnlxfc8 |            ^^^^^^^^^^^^^^^^^^^^^\n
2025-10-31  18:16:22.179 | info | ezqzk1cgnlxfc8 |     return func(*args, **kwargs)\n
2025-10-31  18:16:22.178 | info | ezqzk1cgnlxfc8 |   File "/opt/venv/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context\n
2025-10-31  18:16:22.178 | info | ezqzk1cgnlxfc8 |               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n
2025-10-31  18:16:22.178 | info | ezqzk1cgnlxfc8 |     samples = self.sampler_function(model_k, noise, sigmas, extra_args=extra_args, callback=k_callback, disable=disable_pbar, **self.extra_options)\n
2025-10-31  18:16:22.178 | info | ezqzk1cgnlxfc8 |   File "/comfyui/comfy/samplers.py", line 752, in sample\n
2025-10-31  18:16:22.178 | info | ezqzk1cgnlxfc8 |            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n
2025-10-31  18:16:22.178 | info | ezqzk1cgnlxfc8 |     return self.original(*args, **kwargs)\n
2025-10-31  18:16:22.178 | info | ezqzk1cgnlxfc8 |   File "/comfyui/comfy/patcher_extension.py", line 112, in execute\n
2025-10-31  18:16:22.178 | info | ezqzk1cgnlxfc8 |               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n
2025-10-31  18:16:22.178 | info | ezqzk1cgnlxfc8 |     samples = executor.execute(self, sigmas, extra_args, callback, noise, latent_image, denoise_mask, disable_pbar)\n
2025-10-31  18:16:22.178 | info | ezqzk1cgnlxfc8 |   File "/comfyui/comfy/samplers.py", line 980, in inner_sample\n
2025-10-31  18:16:22.178 | info | ezqzk1cgnlxfc8 |              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n
2025-10-31  18:16:22.178 | info | ezqzk1cgnlxfc8 |     output = self.inner_sample(noise, latent_image, device, sampler, sigmas, denoise_mask, callback, disable_pbar, seed)\n
2025-10-31  18:16:22.178 | info | ezqzk1cgnlxfc8 |   File "/comfyui/comfy/samplers.py", line 997, in outer_sample\n
2025-10-31  18:16:22.178 | info | ezqzk1cgnlxfc8 |            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n
2025-10-31  18:16:22.178 | info | ezqzk1cgnlxfc8 |     return self.original(*args, **kwargs)\n
2025-10-31  18:16:22.178 | info | ezqzk1cgnlxfc8 |   File "/comfyui/comfy/patcher_extension.py", line 112, in execute\n
2025-10-31  18:16:22.178 | info | ezqzk1cgnlxfc8 |              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n
2025-10-31  18:16:22.178 | info | ezqzk1cgnlxfc8 |     output = executor.execute(noise, latent_image, sampler, sigmas, denoise_mask, callback, disable_pbar, seed)\n
2025-10-31  18:16:22.178 | info | ezqzk1cgnlxfc8 |   File "/comfyui/comfy/samplers.py", line 1029, in sample\n
2025-10-31  18:16:22.178 | info | ezqzk1cgnlxfc8 |            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n
2025-10-31  18:16:22.178 | info | ezqzk1cgnlxfc8 |     return cfg_guider.sample(noise, latent_image, sampler, sigmas, denoise_mask, callback, disable_pbar, seed)\n
2025-10-31  18:16:22.178 | info | ezqzk1cgnlxfc8 |   File "/comfyui/comfy/samplers.py", line 1044, in sample\n
2025-10-31  18:16:22.178 | info | ezqzk1cgnlxfc8 |            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n
2025-10-31  18:16:22.178 | info | ezqzk1cgnlxfc8 |     return sample(self.model, noise, positive, negative, cfg, self.device, sampler, sigmas, self.model_options, latent_image=latent_image, denoise_mask=denoise_mask, callback=callback, disable_pbar=disable_pbar, seed=seed)\n
2025-10-31  18:16:22.178 | info | ezqzk1cgnlxfc8 |   File "/comfyui/comfy/samplers.py", line 1154, in sample\n
2025-10-31  18:16:22.178 | info | ezqzk1cgnlxfc8 |               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n
2025-10-31  18:16:22.178 | info | ezqzk1cgnlxfc8 |     samples = sampler.sample(noise, positive, negative, cfg=cfg, latent_image=latent_image, start_step=start_step, last_step=last_step, force_full_denoise=force_full_denoise, denoise_mask=noise_mask, sigmas=sigmas, callback=callback, disable_pbar=disable_pbar, seed=seed)\n
2025-10-31  18:16:22.178 | info | ezqzk1cgnlxfc8 |   File "/comfyui/comfy/sample.py", line 45, in sample\n
2025-10-31  18:16:22.178 | info | ezqzk1cgnlxfc8 |               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n
2025-10-31  18:16:22.177 | info | ezqzk1cgnlxfc8 |     samples = comfy.sample.sample(model, noise, steps, cfg, sampler_name, scheduler, positive, negative, latent_image,\n
2025-10-31  18:16:22.177 | info | ezqzk1cgnlxfc8 |   File "/comfyui/nodes.py", line 1492, in common_ksampler\n
2025-10-31  18:16:22.177 | info | ezqzk1cgnlxfc8 |            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n
2025-10-31  18:16:22.177 | info | ezqzk1cgnlxfc8 |     return common_ksampler(model, noise_seed, steps, cfg, sampler_name, scheduler, positive, negative, latent_image, denoise=denoise, disable_noise=disable_noise, start_step=start_at_step, last_step=end_at_step, force_full_denoise=force_full_denoise)\n
2025-10-31  18:16:22.177 | info | ezqzk1cgnlxfc8 |   File "/comfyui/nodes.py", line 1559, in sample\n
2025-10-31  18:16:22.177 | info | ezqzk1cgnlxfc8 |              ^^^^^^^^^^^\n
2025-10-31  18:16:22.177 | info | ezqzk1cgnlxfc8 |     result = f(**inputs)\n
2025-10-31  18:16:22.177 | info | ezqzk1cgnlxfc8 |   File "/comfyui/execution.py", line 277, in process_inputs\n
2025-10-31  18:16:22.177 | info | ezqzk1cgnlxfc8 |     await process_inputs(input_dict, i)\n
2025-10-31  18:16:22.177 | info | ezqzk1cgnlxfc8 |   File "/comfyui/execution.py", line 289, in _async_map_node_over_list\n
2025-10-31  18:16:22.177 | info | ezqzk1cgnlxfc8 |                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n
2025-10-31  18:16:22.177 | info | ezqzk1cgnlxfc8 |     return_values = await _async_map_node_over_list(prompt_id, unique_id, obj, input_data_all, obj.FUNCTION, allow_interrupt=True, execution_block_cb=execution_block_cb, pre_execute_cb=pre_execute_cb, hidden_inputs=hidden_inputs)\n
2025-10-31  18:16:22.177 | info | ezqzk1cgnlxfc8 |   File "/comfyui/execution.py", line 315, in get_output_data\n
2025-10-31  18:16:22.177 | info | ezqzk1cgnlxfc8 |                                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n
2025-10-31  18:16:22.177 | info | ezqzk1cgnlxfc8 |     output_data, output_ui, has_subgraph, has_pending_tasks = await get_output_data(prompt_id, unique_id, obj, input_data_all, execution_block_cb=execution_block_cb, pre_execute_cb=pre_execute_cb, hidden_inputs=hidden_inputs)\n
2025-10-31  18:16:22.177 | info | ezqzk1cgnlxfc8 |   File "/comfyui/execution.py", line 496, in execute\n
2025-10-31  18:16:22.177 | info | ezqzk1cgnlxfc8 | Traceback (most recent call last):\n
2025-10-31  18:16:22.177 | info | ezqzk1cgnlxfc8 | !!! Exception during processing !!! Command '['/usr/bin/gcc', '/tmp/latentsync_4ca5f8c4/tmpjofwt5tp/cuda_utils.c', '-O3', '-shared', '-fPIC', '-Wno-psabi', '-o', '/tmp/latentsync_4ca5f8c4/tmpjofwt5tp/cuda_utils.cpython-312-x86_64-linux-gnu.so', '-lcuda', '-L/opt/venv/lib/python3.12/site-packages/triton/backends/nvidia/lib', '-L/usr/lib/x86_64-linux-gnu', '-I/opt/venv/lib/python3.12/site-packages/triton/backends/nvidia/include', '-I/tmp/latentsync_4ca5f8c4/tmpjofwt5tp', '-I/usr/include/python3.12']' returned non-zero exit status 1.\n
2025-10-31  18:16:22.177 | info | ezqzk1cgnlxfc8 | Restoring initial comfy attention\n
2025-10-31  18:16:22.177 | info | ezqzk1cgnlxfc8 | \r  0%|          | 0/2 [00:00<?, ?it/s]\n
2025-10-31  18:16:22.177 | info | ezqzk1cgnlxfc8 | compilation terminated.\n
2025-10-31  18:16:22.177 | info | ezqzk1cgnlxfc8 |       |          ^~~~~~~~~~\n
2025-10-31  18:16:22.177 | info | ezqzk1cgnlxfc8 |     6 | #include <Python.h>\n
2025-10-31  18:16:22.060 | info | ezqzk1cgnlxfc8 | \r  0%|          | 0/2 [00:00<?, ?it/s]/tmp/latentsync_4ca5f8c4/tmpjofwt5tp/cuda_utils.c:6:10: fatal error: Python.h: No such file or directory\n
2025-10-31  18:16:21.008 | info | ezqzk1cgnlxfc8 | Patching comfy attention to use sageattn\n
2025-10-31  18:16:17.907 | info | ezqzk1cgnlxfc8 | worker-comfyui - Websocket receive timed out. Still waiting...\n
2025-10-31  18:16:07.897 | info | ezqzk1cgnlxfc8 | worker-comfyui - Websocket receive timed out. Still waiting...\n
2025-10-31  18:15:57.887 | info | ezqzk1cgnlxfc8 | worker-comfyui - Websocket receive timed out. Still waiting...\n
2025-10-31  18:15:47.877 | info | ezqzk1cgnlxfc8 | worker-comfyui - Websocket receive timed out. Still waiting...\n
2025-10-31  18:15:37.867 | info | ezqzk1cgnlxfc8 | worker-comfyui - Websocket receive timed out. Still waiting...\n
2025-10-31  18:15:27.860 | info | ezqzk1cgnlxfc8 | lowvram: loaded module regularly diffusion_model.blocks.20.cross_attn.norm_q RMSNorm((5120,), eps=1e-06, elementwise_affine=True)\n
2025-10-31  18:15:27.860 | info | ezqzk1cgnlxfc8 | lowvram: loaded module regularly diffusion_model.blocks.20.self_attn.norm_k RMSNorm((5120,), eps=1e-06, elementwise_affine=True)\n
2025-10-31  18:15:27.860 | info | ezqzk1cgnlxfc8 | lowvram: loaded module regularly diffusion_model.blocks.20.self_attn.norm_q RMSNorm((5120,), eps=1e-06, elementwise_affine=True)\n
2025-10-31  18:15:27.860 | info | ezqzk1cgnlxfc8 | lowvram: loaded module regularly diffusion_model.blocks.21.cross_attn.norm_k RMSNorm((5120,), eps=1e-06, elementwise_affine=True)\n
2025-10-31  18:15:27.860 | info | ezqzk1cgnlxfc8 | lowvram: loaded module regularly diffusion_model.blocks.21.cross_attn.norm_q RMSNorm((5120,), eps=1e-06, elementwise_affine=True)\n
2025-10-31  18:15:27.860 | info | ezqzk1cgnlxfc8 | lowvram: loaded module regularly diffusion_model.blocks.21.self_attn.norm_k RMSNorm((5120,), eps=1e-06, elementwise_affine=True)\n
2025-10-31  18:15:27.860 | info | ezqzk1cgnlxfc8 | lowvram: loaded module regularly diffusion_model.blocks.21.self_attn.norm_q RMSNorm((5120,), eps=1e-06, elementwise_affine=True)\n
2025-10-31  18:15:27.860 | info | ezqzk1cgnlxfc8 | lowvram: loaded module regularly diffusion_model.blocks.22.cross_attn.norm_k RMSNorm((5120,), eps=1e-06, elementwise_affine=True)\n
2025-10-31  18:15:27.860 | info | ezqzk1cgnlxfc8 | lowvram: loaded module regularly diffusion_model.blocks.22.cross_attn.norm_q RMSNorm((5120,), eps=1e-06, elementwise_affine=True)\n
2025-10-31  18:15:27.860 | info | ezqzk1cgnlxfc8 | lowvram: loaded module regularly diffusion_model.blocks.22.self_attn.norm_k RMSNorm((5120,), eps=1e-06, elementwise_affine=True)\n
2025-10-31  18:15:27.859 | info | ezqzk1cgnlxfc8 | lowvram: loaded module regularly diffusion_model.blocks.22.self_attn.norm_q RMSNorm((5120,), eps=1e-06, elementwise_affine=True)\n
2025-10-31  18:15:27.859 | info | ezqzk1cgnlxfc8 | lowvram: loaded module regularly diffusion_model.blocks.23.cross_attn.norm_k RMSNorm((5120,), eps=1e-06, elementwise_affine=True)\n
2025-10-31  18:15:27.859 | info | ezqzk1cgnlxfc8 | lowvram: loaded module regularly diffusion_model.blocks.23.cross_attn.norm_q RMSNorm((5120,), eps=1e-06, elementwise_affine=True)\n
2025-10-31  18:15:27.859 | info | ezqzk1cgnlxfc8 | lowvram: loaded module regularly diffusion_model.blocks.23.self_attn.norm_k RMSNorm((5120,), eps=1e-06, elementwise_affine=True)\n
2025-10-31  18:15:27.859 | info | ezqzk1cgnlxfc8 | lowvram: loaded module regularly diffusion_model.blocks.23.self_attn.norm_q RMSNorm((5120,), eps=1e-06, elementwise_affine=True)\n
2025-10-31  18:15:27.859 | info | ezqzk1cgnlxfc8 | lowvram: loaded module regularly diffusion_model.blocks.24.cross_attn.norm_k RMSNorm((5120,), eps=1e-06, elementwise_affine=True)\n
2025-10-31  18:15:27.859 | info | ezqzk1cgnlxfc8 | lowvram: loaded module regularly diffusion_model.blocks.24.cross_attn.norm_q RMSNorm((5120,), eps=1e-06, elementwise_affine=True)\n
2025-10-31  18:15:27.859 | info | ezqzk1cgnlxfc8 | lowvram: loaded module regularly diffusion_model.blocks.24.self_attn.norm_k RMSNorm((5120,), eps=1e-06, elementwise_affine=True)\n
2025-10-31  18:15:27.859 | info | ezqzk1cgnlxfc8 | lowvram: loaded module regularly diffusion_model.blocks.24.self_attn.norm_q RMSNorm((5120,), eps=1e-06, elementwise_affine=True)\n
2025-10-31  18:15:27.859 | info | ezqzk1cgnlxfc8 | lowvram: loaded module regularly diffusion_model.blocks.25.cross_attn.norm_k RMSNorm((5120,), eps=1e-06, elementwise_affine=True)\n
2025-10-31  18:15:27.859 | info | ezqzk1cgnlxfc8 | lowvram: loaded module regularly diffusion_model.blocks.25.cross_attn.norm_q RMSNorm((5120,), eps=1e-06, elementwise_affine=True)\n
2025-10-31  18:15:27.859 | info | ezqzk1cgnlxfc8 | lowvram: loaded module regularly diffusion_model.blocks.25.self_attn.norm_k RMSNorm((5120,), eps=1e-06, elementwise_affine=True)\n
2025-10-31  18:15:27.859 | info | ezqzk1cgnlxfc8 | lowvram: loaded module regularly diffusion_model.blocks.25.self_attn.norm_q RMSNorm((5120,), eps=1e-06, elementwise_affine=True)\n
2025-10-31  18:15:27.859 | info | ezqzk1cgnlxfc8 | lowvram: loaded module regularly diffusion_model.blocks.26.cross_attn.norm_k RMSNorm((5120,), eps=1e-06, elementwise_affine=True)\n
2025-10-31  18:15:27.859 | info | ezqzk1cgnlxfc8 | lowvram: loaded module regularly diffusion_model.blocks.26.cross_attn.norm_q RMSNorm((5120,), eps=1e-06, elementwise_affine=True)\n
2025-10-31  18:15:27.859 | info | ezqzk1cgnlxfc8 | lowvram: loaded module regularly diffusion_model.blocks.26.self_attn.norm_k RMSNorm((5120,), eps=1e-06, elementwise_affine=True)\n
2025-10-31  18:15:27.859 | info | ezqzk1cgnlxfc8 | lowvram: loaded module regularly diffusion_model.blocks.26.self_attn.norm_q RMSNorm((5120,), eps=1e-06, elementwise_affine=True)\n
2025-10-31  18:15:27.859 | info | ezqzk1cgnlxfc8 | lowvram: loaded module regularly diffusion_model.blocks.27.cross_attn.norm_k RMSNorm((5120,), eps=1e-06, elementwise_affine=True)\n
2025-10-31  18:15:27.859 | info | ezqzk1cgnlxfc8 | lowvram: loaded module regularly diffusion_model.blocks.27.cross_attn.norm_q RMSNorm((5120,), eps=1e-06, elementwise_affine=True)\n
2025-10-31  18:15:27.859 | info | ezqzk1cgnlxfc8 | lowvram: loaded module regularly diffusion_model.blocks.27.self_attn.norm_k RMSNorm((5120,), eps=1e-06, elementwise_affine=True)\n
2025-10-31  18:15:27.859 | info | ezqzk1cgnlxfc8 | lowvram: loaded module regularly diffusion_model.blocks.27.self_attn.norm_q RMSNorm((5120,), eps=1e-06, elementwise_affine=True)\n
2025-10-31  18:15:27.859 | info | ezqzk1cgnlxfc8 | lowvram: loaded module regularly diffusion_model.blocks.28.cross_attn.norm_k RMSNorm((5120,), eps=1e-06, elementwise_affine=True)\n
2025-10-31  18:15:27.859 | info | ezqzk1cgnlxfc8 | lowvram: loaded module regularly diffusion_model.blocks.28.cross_attn.norm_q RMSNorm((5120,), eps=1e-06, elementwise_affine=True)\n
2025-10-31  18:15:27.858 | info | ezqzk1cgnlxfc8 | lowvram: loaded module regularly diffusion_model.blocks.28.self_attn.norm_k RMSNorm((5120,), eps=1e-06, elementwise_affine=True)\n
2025-10-31  18:15:27.858 | info | ezqzk1cgnlxfc8 | lowvram: loaded module regularly diffusion_model.blocks.28.self_attn.norm_q RMSNorm((5120,), eps=1e-06, elementwise_affine=True)\n
2025-10-31  18:15:27.858 | info | ezqzk1cgnlxfc8 | lowvram: loaded module regularly diffusion_model.blocks.29.cross_attn.norm_k RMSNorm((5120,), eps=1e-06, elementwise_affine=True)\n
2025-10-31  18:15:27.858 | info | ezqzk1cgnlxfc8 | lowvram: loaded module regularly diffusion_model.blocks.29.cross_attn.norm_q RMSNorm((5120,), eps=1e-06, elementwise_affine=True)\n
2025-10-31  18:15:27.858 | info | ezqzk1cgnlxfc8 | lowvram: loaded module regularly diffusion_model.blocks.29.self_attn.norm_k RMSNorm((5120,), eps=1e-06, elementwise_affine=True)\n
2025-10-31  18:15:27.858 | info | ezqzk1cgnlxfc8 | lowvram: loaded module regularly diffusion_model.blocks.29.self_attn.norm_q RMSNorm((5120,), eps=1e-06, elementwise_affine=True)\n
2025-10-31  18:15:27.858 | info | ezqzk1cgnlxfc8 | lowvram: loaded module regularly diffusion_model.blocks.3.cross_attn.norm_k RMSNorm((5120,), eps=1e-06, elementwise_affine=True)\n
2025-10-31  18:15:27.858 | info | ezqzk1cgnlxfc8 | lowvram: loaded module regularly diffusion_model.blocks.3.cross_attn.norm_q RMSNorm((5120,), eps=1e-06, elementwise_affine=True)\n
2025-10-31  18:15:27.858 | info | ezqzk1cgnlxfc8 | lowvram: loaded module regularly diffusion_model.blocks.3.self_attn.norm_k RMSNorm((5120,), eps=1e-06, elementwise_affine=True)\n
2025-10-31  18:15:27.858 | info | ezqzk1cgnlxfc8 | lowvram: loaded module regularly diffusion_model.blocks.3.self_attn.norm_q RMSNorm((5120,), eps=1e-06, elementwise_affine=True)\n
2025-10-31  18:15:27.858 | info | ezqzk1cgnlxfc8 | lowvram: loaded module regularly diffusion_model.blocks.30.cross_attn.norm_k RMSNorm((5120,), eps=1e-06, elementwise_affine=True)\n
2025-10-31  18:15:27.858 | info | ezqzk1cgnlxfc8 | lowvram: loaded module regularly diffusion_model.blocks.30.cross_attn.norm_q RMSNorm((5120,), eps=1e-06, elementwise_affine=True)\n
2025-10-31  18:15:27.858 | info | ezqzk1cgnlxfc8 | lowvram: loaded module regularly diffusion_model.blocks.30.self_attn.norm_k RMSNorm((5120,), eps=1e-06, elementwise_affine=True)\n
2025-10-31  18:15:27.858 | info | ezqzk1cgnlxfc8 | lowvram: loaded module regularly diffusion_model.blocks.30.self_attn.norm_q RMSNorm((5120,), eps=1e-06, elementwise_affine=True)\n
2025-10-31  18:15:27.858 | info | ezqzk1cgnlxfc8 | lowvram: loaded module regularly diffusion_model.blocks.31.cross_attn.norm_k RMSNorm((5120,), eps=1e-06, elementwise_affine=True)\n
2025-10-31  18:15:27.858 | info | ezqzk1cgnlxfc8 | lowvram: loaded module regularly diffusion_model.blocks.31.cross_attn.norm_q RMSNorm((5120,), eps=1e-06, elementwise_affine=True)\n
2025-10-31  18:15:27.858 | info | ezqzk1cgnlxfc8 | lowvram: loaded module regularly diffusion_model.blocks.31.self_attn.norm_k RMSNorm((5120,), eps=1e-06, elementwise_affine=True)\n
2025-10-31  18:15:27.858 | info | ezqzk1cgnlxfc8 | lowvram: loaded module regularly diffusion_model.blocks.31.self_attn.norm_q RMSNorm((5120,), eps=1e-06, elementwise_affine=True)\n
2025-10-31  18:15:27.858 | info | ezqzk1cgnlxfc8 | lowvram: loaded module regularly diffusion_model.blocks.32.cross_attn.norm_k RMSNorm((5120,), eps=1e-06, elementwise_affine=True)\n
2025-10-31  18:15:27.858 | info | ezqzk1cgnlxfc8 | lowvram: loaded module regularly diffusion_model.blocks.32.cross_attn.norm_q RMSNorm((5120,), eps=1e-06, elementwise_affine=True)\n
2025-10-31  18:15:27.858 | info | ezqzk1cgnlxfc8 | lowvram: loaded module regularly diffusion_model.blocks.32.self_attn.norm_k RMSNorm((5120,), eps=1e-06, elementwise_affine=True)\n
2025-10-31  18:15:27.858 | info | ezqzk1cgnlxfc8 | lowvram: loaded module regularly diffusion_model.blocks.32.self_attn.norm_q RMSNorm((5120,), eps=1e-06, elementwise_affine=True)\n
2025-10-31  18:15:27.858 | info | ezqzk1cgnlxfc8 | lowvram: loaded module regularly diffusion_model.blocks.33.cross_attn.norm_k RMSNorm((5120,), eps=1e-06, elementwise_affine=True)\n
2025-10-31  18:15:27.857 | info | ezqzk1cgnlxfc8 | lowvram: loaded module regularly diffusion_model.blocks.33.cross_attn.norm_q RMSNorm((5120,), eps=1e-06, elementwise_affine=True)\n
2025-10-31  18:15:27.857 | info | ezqzk1cgnlxfc8 | lowvram: loaded module regularly diffusion_model.blocks.33.self_attn.norm_k RMSNorm((5120,), eps=1e-06, elementwise_affine=True)\n
2025-10-31  18:15:27.857 | info | ezqzk1cgnlxfc8 | lowvram: loaded module regularly diffusion_model.blocks.33.self_attn.norm_q RMSNorm((5120,), eps=1e-06, elementwise_affine=True)\n
2025-10-31  18:15:27.857 | info | ezqzk1cgnlxfc8 | lowvram: loaded module regularly diffusion_model.blocks.34.cross_attn.norm_k RMSNorm((5120,), eps=1e-06, elementwise_affine=True)\n
2025-10-31  18:15:27.857 | info | ezqzk1cgnlxfc8 | lowvram: loaded module regularly diffusion_model.blocks.34.cross_attn.norm_q RMSNorm((5120,), eps=1e-06, elementwise_affine=True)\n
2025-10-31  18:15:27.857 | info | ezqzk1cgnlxfc8 | lowvram: loaded module regularly diffusion_model.blocks.34.self_attn.norm_k RMSNorm((5120,), eps=1e-06, elementwise_affine=True)\n
2025-10-31  18:15:27.857 | info | ezqzk1cgnlxfc8 | lowvram: loaded module regularly diffusion_model.blocks.34.self_attn.norm_q RMSNorm((5120,), eps=1e-06, elementwise_affine=True)\n
2025-10-31  18:15:27.857 | info | ezqzk1cgnlxfc8 | lowvram: loaded module regularly diffusion_model.blocks.35.cross_attn.norm_k RMSNorm((5120,), eps=1e-06, elementwise_affine=True)\n
2025-10-31  18:15:27.857 | info | ezqzk1cgnlxfc8 | lowvram: loaded module regularly diffusion_model.blocks.35.cross_attn.norm_q RMSNorm((5120,), eps=1e-06, elementwise_affine=True)\n
2025-10-31  18:15:27.857 | info | ezqzk1cgnlxfc8 | lowvram: loaded module regularly diffusion_model.blocks.35.self_attn.norm_k RMSNorm((5120,), eps=1e-06, elementwise_affine=True)\n
2025-10-31  18:15:27.857 | info | ezqzk1cgnlxfc8 | lowvram: loaded module regularly diffusion_model.blocks.35.self_attn.norm_q RMSNorm((5120,), eps=1e-06, elementwise_affine=True)\n
2025-10-31  18:15:27.857 | info | ezqzk1cgnlxfc8 | lowvram: loaded module regularly diffusion_model.blocks.36.cross_attn.norm_k RMSNorm((5120,), eps=1e-06, elementwise_affine=True)\n
2025-10-31  18:15:27.857 | info | ezqzk1cgnlxfc8 | lowvram: loaded module regularly diffusion_model.blocks.36.cross_attn.norm_q RMSNorm((5120,), eps=1e-06, elementwise_affine=True)\n
2025-10-31  18:15:27.857 | info | ezqzk1cgnlxfc8 | lowvram: loaded module regularly diffusion_model.blocks.36.self_attn.norm_k RMSNorm((5120,), eps=1e-06, elementwise_affine=True)\n
2025-10-31  18:15:27.857 | info | ezqzk1cgnlxfc8 | lowvram: loaded module regularly diffusion_model.blocks.36.self_attn.norm_q RMSNorm((5120,), eps=1e-06, elementwise_affine=True)\n
2025-10-31  18:15:24.710 | info | ezqzk1cgnlxfc8 | lowvram: loaded module regularly diffusion_model.blocks.37.cross_attn.norm_k RMSNorm((5120,), eps=1e-06, elementwise_affine=True)\n
2025-10-31  18:15:24.710 | info | ezqzk1cgnlxfc8 | lowvram: loaded module regularly diffusion_model.blocks.37.cross_attn.norm_q RMSNorm((5120,), eps=1e-06, elementwise_affine=True)\n
2025-10-31  18:15:24.710 | info | ezqzk1cgnlxfc8 | lowvram: loaded module regularly diffusion_model.blocks.37.self_attn.norm_k RMSNorm((5120,), eps=1e-06, elementwise_affine=True)\n
2025-10-31  18:15:24.710 | info | ezqzk1cgnlxfc8 | lowvram: loaded module regularly diffusion_model.blocks.37.self_attn.norm_q RMSNorm((5120,), eps=1e-06, elementwise_affine=True)\n
2025-10-31  18:15:24.710 | info | ezqzk1cgnlxfc8 | lowvram: loaded module regularly diffusion_model.blocks.38.cross_attn.norm_k RMSNorm((5120,), eps=1e-06, elementwise_affine=True)\n
2025-10-31  18:15:24.710 | info | ezqzk1cgnlxfc8 | lowvram: loaded module regularly diffusion_model.blocks.38.cross_attn.norm_q RMSNorm((5120,), eps=1e-06, elementwise_affine=True)\n
2025-10-31  18:15:24.709 | info | ezqzk1cgnlxfc8 | lowvram: loaded module regularly diffusion_model.blocks.38.self_attn.norm_k RMSNorm((5120,), eps=1e-06, elementwise_affine=True)\n
2025-10-31  18:15:24.709 | info | ezqzk1cgnlxfc8 | lowvram: loaded module regularly diffusion_model.blocks.38.self_attn.norm_q RMSNorm((5120,), eps=1e-06, elementwise_affine=True)\n
2025-10-31  18:15:24.709 | info | ezqzk1cgnlxfc8 | lowvram: loaded module regularly diffusion_model.blocks.39.cross_attn.norm_k RMSNorm((5120,), eps=1e-06, elementwise_affine=True)\n
2025-10-31  18:15:24.709 | info | ezqzk1cgnlxfc8 | lowvram: loaded module regularly diffusion_model.blocks.39.cross_attn.norm_q RMSNorm((5120,), eps=1e-06, elementwise_affine=True)\n
2025-10-31  18:15:24.709 | info | ezqzk1cgnlxfc8 | lowvram: loaded module regularly diffusion_model.blocks.39.self_attn.norm_k RMSNorm((5120,), eps=1e-06, elementwise_affine=True)\n
2025-10-31  18:15:24.709 | info | ezqzk1cgnlxfc8 | lowvram: loaded module regularly diffusion_model.blocks.39.self_attn.norm_q RMSNorm((5120,), eps=1e-06, elementwise_affine=True)\n
2025-10-31  18:15:24.709 | info | ezqzk1cgnlxfc8 | lowvram: loaded module regularly diffusion_model.blocks.4.cross_attn.norm_k RMSNorm((5120,), eps=1e-06, elementwise_affine=True)\n
2025-10-31  18:15:24.709 | info | ezqzk1cgnlxfc8 | lowvram: loaded module regularly diffusion_model.blocks.4.cross_attn.norm_q RMSNorm((5120,), eps=1e-06, elementwise_affine=True)\n
2025-10-31  18:15:24.709 | info | ezqzk1cgnlxfc8 | lowvram: loaded module regularly diffusion_model.blocks.4.self_attn.norm_k RMSNorm((5120,), eps=1e-06, elementwise_affine=True)\n
2025-10-31  18:15:24.709 | info | ezqzk1cgnlxfc8 | lowvram: loaded module regularly diffusion_model.blocks.4.self_attn.norm_q RMSNorm((5120,), eps=1e-06, elementwise_affine=True)\n
2025-10-31  18:15:24.709 | info | ezqzk1cgnlxfc8 | lowvram: loaded module regularly diffusion_model.blocks.5.cross_attn.norm_k RMSNorm((5120,), eps=1e-06, elementwise_affine=True)\n
2025-10-31  18:15:24.709 | info | ezqzk1cgnlxfc8 | lowvram: loaded module regularly diffusion_model.blocks.5.cross_attn.norm_q RMSNorm((5120,), eps=1e-06, elementwise_affine=True)\n
2025-10-31  18:15:24.709 | info | ezqzk1cgnlxfc8 | lowvram: loaded module regularly diffusion_model.blocks.5.self_attn.norm_k RMSNorm((5120,), eps=1e-06, elementwise_affine=True)\n
2025-10-31  18:15:24.709 | info | ezqzk1cgnlxfc8 | lowvram: loaded module regularly diffusion_model.blocks.5.self_attn.norm_q RMSNorm((5120,), eps=1e-06, elementwise_affine=True)\n
2025-10-31  18:15:24.709 | info | ezqzk1cgnlxfc8 | lowvram: loaded module regularly diffusion_model.blocks.6.cross_attn.norm_k RMSNorm((5120,), eps=1e-06, elementwise_affine=True)\n
2025-10-31  18:15:24.709 | info | ezqzk1cgnlxfc8 | lowvram: loaded module regularly diffusion_model.blocks.6.cross_attn.norm_q RMSNorm((5120,), eps=1e-06, elementwise_affine=True)\n
2025-10-31  18:15:24.709 | info | ezqzk1cgnlxfc8 | lowvram: loaded module regularly diffusion_model.blocks.6.self_attn.norm_k RMSNorm((5120,), eps=1e-06, elementwise_affine=True)\n
2025-10-31  18:15:24.709 | info | ezqzk1cgnlxfc8 | lowvram: loaded module regularly diffusion_model.blocks.6.self_attn.norm_q RMSNorm((5120,), eps=1e-06, elementwise_affine=True)\n
2025-10-31  18:15:24.709 | info | ezqzk1cgnlxfc8 | lowvram: loaded module regularly diffusion_model.blocks.7.cross_attn.norm_k RMSNorm((5120,), eps=1e-06, elementwise_affine=True)\n
2025-10-31  18:15:24.709 | info | ezqzk1cgnlxfc8 | lowvram: loaded module regularly diffusion_model.blocks.7.cross_attn.norm_q RMSNorm((5120,), eps=1e-06, elementwise_affine=True)\n
2025-10-31  18:15:24.709 | info | ezqzk1cgnlxfc8 | lowvram: loaded module regularly diffusion_model.blocks.7.self_attn.norm_k RMSNorm((5120,), eps=1e-06, elementwise_affine=True)\n
2025-10-31  18:15:24.709 | info | ezqzk1cgnlxfc8 | lowvram: loaded module regularly diffusion_model.blocks.7.self_attn.norm_q RMSNorm((5120,), eps=1e-06, elementwise_affine=True)\n
2025-10-31  18:15:24.709 | info | ezqzk1cgnlxfc8 | lowvram: loaded module regularly diffusion_model.blocks.8.cross_attn.norm_k RMSNorm((5120,), eps=1e-06, elementwise_affine=True)\n
2025-10-31  18:15:24.709 | info | ezqzk1cgnlxfc8 | lowvram: loaded module regularly diffusion_model.blocks.8.cross_attn.norm_q RMSNorm((5120,), eps=1e-06, elementwise_affine=True)\n
2025-10-31  18:15:24.709 | info | ezqzk1cgnlxfc8 | lowvram: loaded module regularly diffusion_model.blocks.8.self_attn.norm_k RMSNorm((5120,), eps=1e-06, elementwise_affine=True)\n
2025-10-31  18:15:24.708 | info | ezqzk1cgnlxfc8 | lowvram: loaded module regularly diffusion_model.blocks.8.self_attn.norm_q RMSNorm((5120,), eps=1e-06, elementwise_affine=True)\n
2025-10-31  18:15:24.708 | info | ezqzk1cgnlxfc8 | lowvram: loaded module regularly diffusion_model.blocks.9.cross_attn.norm_k RMSNorm((5120,), eps=1e-06, elementwise_affine=True)\n
2025-10-31  18:15:24.708 | info | ezqzk1cgnlxfc8 | lowvram: loaded module regularly diffusion_model.blocks.9.cross_attn.norm_q RMSNorm((5120,), eps=1e-06, elementwise_affine=True)\n
2025-10-31  18:15:24.708 | info | ezqzk1cgnlxfc8 | lowvram: loaded module regularly diffusion_model.blocks.9.self_attn.norm_k RMSNorm((5120,), eps=1e-06, elementwise_affine=True)\n
2025-10-31  18:15:24.708 | info | ezqzk1cgnlxfc8 | lowvram: loaded module regularly diffusion_model.blocks.9.self_attn.norm_q RMSNorm((5120,), eps=1e-06, elementwise_affine=True)\n
2025-10-31  18:15:24.708 | info | ezqzk1cgnlxfc8 | lowvram: loaded module regularly diffusion_model.blocks.0.norm3 LayerNorm((5120,), eps=1e-06, elementwise_affine=True)\n
2025-10-31  18:15:24.708 | info | ezqzk1cgnlxfc8 | lowvram: loaded module regularly diffusion_model.blocks.1.norm3 LayerNorm((5120,), eps=1e-06, elementwise_affine=True)\n
2025-10-31  18:15:24.708 | info | ezqzk1cgnlxfc8 | lowvram: loaded module regularly diffusion_model.blocks.10.norm3 LayerNorm((5120,), eps=1e-06, elementwise_affine=True)\n
2025-10-31  18:15:24.708 | info | ezqzk1cgnlxfc8 | lowvram: loaded module regularly diffusion_model.blocks.11.norm3 LayerNorm((5120,), eps=1e-06, elementwise_affine=True)\n
2025-10-31  18:15:24.708 | info | ezqzk1cgnlxfc8 | lowvram: loaded module regularly diffusion_model.blocks.12.norm3 LayerNorm((5120,), eps=1e-06, elementwise_affine=True)\n
2025-10-31  18:15:24.708 | info | ezqzk1cgnlxfc8 | lowvram: loaded module regularly diffusion_model.blocks.13.norm3 LayerNorm((5120,), eps=1e-06, elementwise_affine=True)\n
2025-10-31  18:15:24.708 | info | ezqzk1cgnlxfc8 | lowvram: loaded module regularly diffusion_model.blocks.14.norm3 LayerNorm((5120,), eps=1e-06, elementwise_affine=True)\n
2025-10-31  18:15:24.708 | info | ezqzk1cgnlxfc8 | lowvram: loaded module regularly diffusion_model.blocks.15.norm3 LayerNorm((5120,), eps=1e-06, elementwise_affine=True)\n
2025-10-31  18:15:24.708 | info | ezqzk1cgnlxfc8 | lowvram: loaded module regularly diffusion_model.blocks.16.norm3 LayerNorm((5120,), eps=1e-06, elementwise_affine=True)\n
2025-10-31  18:15:24.708 | info | ezqzk1cgnlxfc8 | lowvram: loaded module regularly diffusion_model.blocks.17.norm3 LayerNorm((5120,), eps=1e-06, elementwise_affine=True)\n
2025-10-31  18:15:24.708 | info | ezqzk1cgnlxfc8 | lowvram: loaded module regularly diffusion_model.blocks.18.norm3 LayerNorm((5120,), eps=1e-06, elementwise_affine=True)\n
2025-10-31  18:15:24.708 | info | ezqzk1cgnlxfc8 | lowvram: loaded module regularly diffusion_model.blocks.19.norm3 LayerNorm((5120,), eps=1e-06, elementwise_affine=True)\n
2025-10-31  18:15:24.708 | info | ezqzk1cgnlxfc8 | lowvram: loaded module regularly diffusion_model.blocks.2.norm3 LayerNorm((5120,), eps=1e-06, elementwise_affine=True)\n
2025-10-31  18:15:24.708 | info | ezqzk1cgnlxfc8 | lowvram: loaded module regularly diffusion_model.blocks.20.norm3 LayerNorm((5120,), eps=1e-06, elementwise_affine=True)\n
2025-10-31  18:15:24.708 | info | ezqzk1cgnlxfc8 | lowvram: loaded module regularly diffusion_model.blocks.21.norm3 LayerNorm((5120,), eps=1e-06, elementwise_affine=True)\n
2025-10-31  18:15:24.708 | info | ezqzk1cgnlxfc8 | lowvram: loaded module regularly diffusion_model.blocks.22.norm3 LayerNorm((5120,), eps=1e-06, elementwise_affine=True)\n
2025-10-31  18:15:24.708 | info | ezqzk1cgnlxfc8 | lowvram: loaded module regularly diffusion_model.blocks.23.norm3 LayerNorm((5120,), eps=1e-06, elementwise_affine=True)\n
2025-10-31  18:15:24.708 | info | ezqzk1cgnlxfc8 | lowvram: loaded module regularly diffusion_model.blocks.24.norm3 LayerNorm((5120,), eps=1e-06, elementwise_affine=True)\n
2025-10-31  18:15:24.708 | info | ezqzk1cgnlxfc8 | lowvram: loaded module regularly diffusion_model.blocks.25.norm3 LayerNorm((5120,), eps=1e-06, elementwise_affine=True)\n
2025-10-31  18:15:24.708 | info | ezqzk1cgnlxfc8 | lowvram: loaded module regularly diffusion_model.blocks.26.norm3 LayerNorm((5120,), eps=1e-06, elementwise_affine=True)\n
2025-10-31  18:15:24.708 | info | ezqzk1cgnlxfc8 | lowvram: loaded module regularly diffusion_model.blocks.27.norm3 LayerNorm((5120,), eps=1e-06, elementwise_affine=True)\n
2025-10-31  18:15:24.708 | info | ezqzk1cgnlxfc8 | lowvram: loaded module regularly diffusion_model.blocks.28.norm3 LayerNorm((5120,), eps=1e-06, elementwise_affine=True)\n
2025-10-31  18:15:24.708 | info | ezqzk1cgnlxfc8 | lowvram: loaded module regularly diffusion_model.blocks.29.norm3 LayerNorm((5120,), eps=1e-06, elementwise_affine=True)\n
2025-10-31  18:15:24.707 | info | ezqzk1cgnlxfc8 | lowvram: loaded module regularly diffusion_model.blocks.3.norm3 LayerNorm((5120,), eps=1e-06, elementwise_affine=True)\n
2025-10-31  18:15:24.707 | info | ezqzk1cgnlxfc8 | lowvram: loaded module regularly diffusion_model.blocks.30.norm3 LayerNorm((5120,), eps=1e-06, elementwise_affine=True)\n
2025-10-31  18:15:24.707 | info | ezqzk1cgnlxfc8 | lowvram: loaded module regularly diffusion_model.blocks.31.norm3 LayerNorm((5120,), eps=1e-06, elementwise_affine=True)\n
2025-10-31  18:15:24.707 | info | ezqzk1cgnlxfc8 | lowvram: loaded module regularly diffusion_model.blocks.32.norm3 LayerNorm((5120,), eps=1e-06, elementwise_affine=True)\n
2025-10-31  18:15:24.707 | info | ezqzk1cgnlxfc8 | lowvram: loaded module regularly diffusion_model.blocks.33.norm3 LayerNorm((5120,), eps=1e-06, elementwise_affine=True)\n
2025-10-31  18:15:24.707 | info | ezqzk1cgnlxfc8 | lowvram: loaded module regularly diffusion_model.blocks.34.norm3 LayerNorm((5120,), eps=1e-06, elementwise_affine=True)\n
2025-10-31  18:15:24.707 | info | ezqzk1cgnlxfc8 | lowvram: loaded module regularly diffusion_model.blocks.35.norm3 LayerNorm((5120,), eps=1e-06, elementwise_affine=True)\n
2025-10-31  18:15:24.707 | info | ezqzk1cgnlxfc8 | lowvram: loaded module regularly diffusion_model.blocks.36.norm3 LayerNorm((5120,), eps=1e-06, elementwise_affine=True)\n
2025-10-31  18:15:24.707 | info | ezqzk1cgnlxfc8 | lowvram: loaded module regularly diffusion_model.blocks.37.norm3 LayerNorm((5120,), eps=1e-06, elementwise_affine=True)\n
2025-10-31  18:15:24.707 | info | ezqzk1cgnlxfc8 | lowvram: loaded module regularly diffusion_model.blocks.38.norm3 LayerNorm((5120,), eps=1e-06, elementwise_affine=True)\n
2025-10-31  18:15:24.707 | info | ezqzk1cgnlxfc8 | lowvram: loaded module regularly diffusion_model.blocks.39.norm3 LayerNorm((5120,), eps=1e-06, elementwise_affine=True)\n
2025-10-31  18:15:24.707 | info | ezqzk1cgnlxfc8 | lowvram: loaded module regularly diffusion_model.blocks.4.norm3 LayerNorm((5120,), eps=1e-06, elementwise_affine=True)\n
2025-10-31  18:15:24.707 | info | ezqzk1cgnlxfc8 | lowvram: loaded module regularly diffusion_model.blocks.5.norm3 LayerNorm((5120,), eps=1e-06, elementwise_affine=True)\n
2025-10-31  18:15:24.707 | info | ezqzk1cgnlxfc8 | lowvram: loaded module regularly diffusion_model.blocks.6.norm3 LayerNorm((5120,), eps=1e-06, elementwise_affine=True)\n
2025-10-31  18:15:24.707 | info | ezqzk1cgnlxfc8 | lowvram: loaded module regularly diffusion_model.blocks.7.norm3 LayerNorm((5120,), eps=1e-06, elementwise_affine=True)\n
2025-10-31  18:15:24.707 | info | ezqzk1cgnlxfc8 | lowvram: loaded module regularly diffusion_model.blocks.8.norm3 LayerNorm((5120,), eps=1e-06, elementwise_affine=True)\n
2025-10-31  18:15:24.707 | info | ezqzk1cgnlxfc8 | lowvram: loaded module regularly diffusion_model.blocks.9.norm3 LayerNorm((5120,), eps=1e-06, elementwise_affine=True)\n
2025-10-31  18:15:24.707 | info | ezqzk1cgnlxfc8 | lowvram: loaded module regularly diffusion_model.head.head Linear(in_features=5120, out_features=64, bias=True)\n
2025-10-31  18:15:24.607 | info | ezqzk1cgnlxfc8 | lowvram: loaded module regularly diffusion_model.time_embedding.0 Linear(in_features=256, out_features=5120, bias=True)\n
2025-10-31  18:15:24.607 | info | ezqzk1cgnlxfc8 | lowvram: loaded module regularly diffusion_model.patch_embedding Conv3d(36, 5120, kernel_size=(1, 2, 2), stride=(1, 2, 2))\n
2025-10-31  18:15:24.607 | info | ezqzk1cgnlxfc8 | lowvram: loaded module regularly diffusion_model.blocks.9.self_attn.v Linear(in_features=5120, out_features=5120, bias=True)\n
2025-10-31  18:15:24.446 | info | ezqzk1cgnlxfc8 | lowvram: loaded module regularly diffusion_model.text_embedding.2 Linear(in_features=5120, out_features=5120, bias=True)\n
2025-10-31  18:15:24.332 | info | ezqzk1cgnlxfc8 | lowvram: loaded module regularly diffusion_model.time_embedding.2 Linear(in_features=5120, out_features=5120, bias=True)\n
2025-10-31  18:15:21.527 | info | ezqzk1cgnlxfc8 | 0 models unloaded.\n
2025-10-31  18:15:20.801 | info | ezqzk1cgnlxfc8 | Unloading WanVAE\n
2025-10-31  18:15:20.801 | info | ezqzk1cgnlxfc8 | Unloading WanTEModel\n
2025-10-31  18:15:17.917 | info | ezqzk1cgnlxfc8 | Requested to load WAN21\n
2025-10-31  18:15:17.917 | info | ezqzk1cgnlxfc8 | adm 0\n
2025-10-31  18:15:17.917 | info | ezqzk1cgnlxfc8 | model_type FLOW\n
2025-10-31  18:15:17.917 | info | ezqzk1cgnlxfc8 | model weight dtype torch.float16, manual cast: None\n
2025-10-31  18:15:14.434 | info | ezqzk1cgnlxfc8 | gguf qtypes: F16 (694), Q5_K (400), F32 (1)\n
2025-10-31  18:15:05.392 | info | ezqzk1cgnlxfc8 | worker-comfyui - Websocket receive timed out. Still waiting...\n
2025-10-31  18:14:55.384 | info | ezqzk1cgnlxfc8 | lowvram: loaded module regularly decoder.upsamples.7.time_conv CausalConv3d(384, 768, kernel_size=(3, 1, 1), stride=(1, 1, 1))\n
2025-10-31  18:14:55.384 | info | ezqzk1cgnlxfc8 | lowvram: loaded module regularly decoder.upsamples.10.residual.2 CausalConv3d(192, 192, kernel_size=(3, 3, 3), stride=(1, 1, 1))\n
2025-10-31  18:14:55.384 | info | ezqzk1cgnlxfc8 | lowvram: loaded module regularly decoder.upsamples.10.residual.6 CausalConv3d(192, 192, kernel_size=(3, 3, 3), stride=(1, 1, 1))\n
2025-10-31  18:14:55.384 | info | ezqzk1cgnlxfc8 | lowvram: loaded module regularly decoder.upsamples.8.residual.2 CausalConv3d(192, 192, kernel_size=(3, 3, 3), stride=(1, 1, 1))\n
2025-10-31  18:14:55.384 | info | ezqzk1cgnlxfc8 | lowvram: loaded module regularly decoder.upsamples.8.residual.6 CausalConv3d(192, 192, kernel_size=(3, 3, 3), stride=(1, 1, 1))\n
2025-10-31  18:14:55.384 | info | ezqzk1cgnlxfc8 | lowvram: loaded module regularly decoder.upsamples.9.residual.2 CausalConv3d(192, 192, kernel_size=(3, 3, 3), stride=(1, 1, 1))\n
2025-10-31  18:14:55.384 | info | ezqzk1cgnlxfc8 | lowvram: loaded module regularly decoder.upsamples.9.residual.6 CausalConv3d(192, 192, kernel_size=(3, 3, 3), stride=(1, 1, 1))\n
2025-10-31  18:14:55.384 | info | ezqzk1cgnlxfc8 | lowvram: loaded module regularly encoder.downsamples.3.residual.6 CausalConv3d(192, 192, kernel_size=(3, 3, 3), stride=(1, 1, 1))\n
2025-10-31  18:14:55.384 | info | ezqzk1cgnlxfc8 | lowvram: loaded module regularly encoder.downsamples.4.residual.2 CausalConv3d(192, 192, kernel_size=(3, 3, 3), stride=(1, 1, 1))\n
2025-10-31  18:14:55.384 | info | ezqzk1cgnlxfc8 | lowvram: loaded module regularly encoder.downsamples.4.residual.6 CausalConv3d(192, 192, kernel_size=(3, 3, 3), stride=(1, 1, 1))\n
2025-10-31  18:14:55.384 | info | ezqzk1cgnlxfc8 | lowvram: loaded module regularly encoder.downsamples.8.resample.1 Conv2d(384, 384, kernel_size=(3, 3), stride=(2, 2))\n
2025-10-31  18:14:55.384 | info | ezqzk1cgnlxfc8 | lowvram: loaded module regularly decoder.upsamples.4.residual.2 CausalConv3d(192, 384, kernel_size=(3, 3, 3), stride=(1, 1, 1))\n
2025-10-31  18:14:55.384 | info | ezqzk1cgnlxfc8 | lowvram: loaded module regularly encoder.downsamples.6.residual.2 CausalConv3d(192, 384, kernel_size=(3, 3, 3), stride=(1, 1, 1))\n
2025-10-31  18:14:55.384 | info | ezqzk1cgnlxfc8 | lowvram: loaded module regularly decoder.middle.0.residual.2 CausalConv3d(384, 384, kernel_size=(3, 3, 3), stride=(1, 1, 1))\n
2025-10-31  18:14:55.384 | info | ezqzk1cgnlxfc8 | lowvram: loaded module regularly decoder.middle.0.residual.6 CausalConv3d(384, 384, kernel_size=(3, 3, 3), stride=(1, 1, 1))\n
2025-10-31  18:14:55.384 | info | ezqzk1cgnlxfc8 | lowvram: loaded module regularly decoder.middle.2.residual.2 CausalConv3d(384, 384, kernel_size=(3, 3, 3), stride=(1, 1, 1))\n
2025-10-31  18:14:55.384 | info | ezqzk1cgnlxfc8 | lowvram: loaded module regularly decoder.middle.2.residual.6 CausalConv3d(384, 384, kernel_size=(3, 3, 3), stride=(1, 1, 1))\n
2025-10-31  18:14:55.383 | info | ezqzk1cgnlxfc8 | lowvram: loaded module regularly decoder.upsamples.0.residual.2 CausalConv3d(384, 384, kernel_size=(3, 3, 3), stride=(1, 1, 1))\n
2025-10-31  18:14:55.383 | info | ezqzk1cgnlxfc8 | lowvram: loaded module regularly decoder.upsamples.0.residual.6 CausalConv3d(384, 384, kernel_size=(3, 3, 3), stride=(1, 1, 1))\n
2025-10-31  18:14:55.383 | info | ezqzk1cgnlxfc8 | lowvram: loaded module regularly decoder.upsamples.1.residual.2 CausalConv3d(384, 384, kernel_size=(3, 3, 3), stride=(1, 1, 1))\n
2025-10-31  18:14:55.383 | info | ezqzk1cgnlxfc8 | lowvram: loaded module regularly decoder.upsamples.1.residual.6 CausalConv3d(384, 384, kernel_size=(3, 3, 3), stride=(1, 1, 1))\n
2025-10-31  18:14:55.383 | info | ezqzk1cgnlxfc8 | lowvram: loaded module regularly decoder.upsamples.2.residual.2 CausalConv3d(384, 384, kernel_size=(3, 3, 3), stride=(1, 1, 1))\n
2025-10-31  18:14:55.383 | info | ezqzk1cgnlxfc8 | lowvram: loaded module regularly decoder.upsamples.2.residual.6 CausalConv3d(384, 384, kernel_size=(3, 3, 3), stride=(1, 1, 1))\n
2025-10-31  18:14:55.383 | info | ezqzk1cgnlxfc8 | lowvram: loaded module regularly decoder.upsamples.4.residual.6 CausalConv3d(384, 384, kernel_size=(3, 3, 3), stride=(1, 1, 1))\n
2025-10-31  18:14:55.383 | info | ezqzk1cgnlxfc8 | lowvram: loaded module regularly decoder.upsamples.5.residual.2 CausalConv3d(384, 384, kernel_size=(3, 3, 3), stride=(1, 1, 1))\n
2025-10-31  18:14:55.383 | info | ezqzk1cgnlxfc8 | lowvram: loaded module regularly decoder.upsamples.5.residual.6 CausalConv3d(384, 384, kernel_size=(3, 3, 3), stride=(1, 1, 1))\n
2025-10-31  18:14:55.383 | info | ezqzk1cgnlxfc8 | lowvram: loaded module regularly decoder.upsamples.6.residual.2 CausalConv3d(384, 384, kernel_size=(3, 3, 3), stride=(1, 1, 1))\n
2025-10-31  18:14:55.383 | info | ezqzk1cgnlxfc8 | lowvram: loaded module regularly decoder.upsamples.6.residual.6 CausalConv3d(384, 384, kernel_size=(3, 3, 3), stride=(1, 1, 1))\n
2025-10-31  18:14:55.383 | info | ezqzk1cgnlxfc8 | lowvram: loaded module regularly encoder.downsamples.10.residual.2 CausalConv3d(384, 384, kernel_size=(3, 3, 3), stride=(1, 1, 1))\n
2025-10-31  18:14:55.383 | info | ezqzk1cgnlxfc8 | lowvram: loaded module regularly encoder.downsamples.10.residual.6 CausalConv3d(384, 384, kernel_size=(3, 3, 3), stride=(1, 1, 1))\n
2025-10-31  18:14:55.383 | info | ezqzk1cgnlxfc8 | lowvram: loaded module regularly encoder.downsamples.6.residual.6 CausalConv3d(384, 384, kernel_size=(3, 3, 3), stride=(1, 1, 1))\n
2025-10-31  18:14:55.383 | info | ezqzk1cgnlxfc8 | lowvram: loaded module regularly encoder.downsamples.7.residual.2 CausalConv3d(384, 384, kernel_size=(3, 3, 3), stride=(1, 1, 1))\n
2025-10-31  18:14:55.383 | info | ezqzk1cgnlxfc8 | lowvram: loaded module regularly encoder.downsamples.7.residual.6 CausalConv3d(384, 384, kernel_size=(3, 3, 3), stride=(1, 1, 1))\n
2025-10-31  18:14:55.383 | info | ezqzk1cgnlxfc8 | lowvram: loaded module regularly encoder.downsamples.9.residual.2 CausalConv3d(384, 384, kernel_size=(3, 3, 3), stride=(1, 1, 1))\n
2025-10-31  18:14:55.383 | info | ezqzk1cgnlxfc8 | lowvram: loaded module regularly encoder.downsamples.9.residual.6 CausalConv3d(384, 384, kernel_size=(3, 3, 3), stride=(1, 1, 1))\n
2025-10-31  18:14:55.383 | info | ezqzk1cgnlxfc8 | lowvram: loaded module regularly encoder.middle.0.residual.2 CausalConv3d(384, 384, kernel_size=(3, 3, 3), stride=(1, 1, 1))\n
2025-10-31  18:14:55.383 | info | ezqzk1cgnlxfc8 | lowvram: loaded module regularly encoder.middle.0.residual.6 CausalConv3d(384, 384, kernel_size=(3, 3, 3), stride=(1, 1, 1))\n
2025-10-31  18:14:55.383 | info | ezqzk1cgnlxfc8 | lowvram: loaded module regularly encoder.middle.2.residual.2 CausalConv3d(384, 384, kernel_size=(3, 3, 3), stride=(1, 1, 1))\n
2025-10-31  18:14:55.383 | info | ezqzk1cgnlxfc8 | lowvram: loaded module regularly encoder.middle.2.residual.6 CausalConv3d(384, 384, kernel_size=(3, 3, 3), stride=(1, 1, 1))\n
2025-10-31  18:14:47.565 | info | ezqzk1cgnlxfc8 | freed umt5xxl.transformer.encoder.block.13.layer.1.DenseReluDense.wo\n
2025-10-31  18:14:47.336 | info | ezqzk1cgnlxfc8 | freed umt5xxl.transformer.encoder.block.11.layer.1.DenseReluDense.wi_0\n
2025-10-31  18:14:47.222 | info | ezqzk1cgnlxfc8 | freed umt5xxl.transformer.encoder.block.1.layer.1.DenseReluDense.wo\n
2025-10-31  18:14:46.995 | info | ezqzk1cgnlxfc8 | freed umt5xxl.transformer.encoder.block.8.layer.0.SelfAttention.o\n
2025-10-31  18:14:46.784 | info | ezqzk1cgnlxfc8 | freed umt5xxl.transformer.encoder.block.3.layer.0.SelfAttention.v\n
2025-10-31  18:14:46.579 | info | ezqzk1cgnlxfc8 | freed umt5xxl.transformer.encoder.block.20.layer.0.SelfAttention.o\n
2025-10-31  18:14:46.372 | info | ezqzk1cgnlxfc8 | freed umt5xxl.transformer.encoder.block.16.layer.0.SelfAttention.v\n
2025-10-31  18:14:46.153 | info | ezqzk1cgnlxfc8 | freed umt5xxl.transformer.encoder.block.12.layer.0.SelfAttention.o\n
2025-10-31  18:14:45.947 | info | ezqzk1cgnlxfc8 | freed umt5xxl.transformer.encoder.block.16.layer.0.SelfAttention.relative_attention_bias\n
2025-10-31  18:14:45.947 | info | ezqzk1cgnlxfc8 | freed umt5xxl.transformer.encoder.block.15.layer.0.SelfAttention.relative_attention_bias\n
2025-10-31  18:14:45.947 | info | ezqzk1cgnlxfc8 | freed umt5xxl.transformer.encoder.block.14.layer.0.SelfAttention.relative_attention_bias\n
2025-10-31  18:14:45.947 | info | ezqzk1cgnlxfc8 | freed umt5xxl.transformer.encoder.block.13.layer.0.SelfAttention.relative_attention_bias\n
2025-10-31  18:14:45.947 | info | ezqzk1cgnlxfc8 | freed umt5xxl.transformer.encoder.block.12.layer.0.SelfAttention.relative_attention_bias\n
2025-10-31  18:14:45.947 | info | ezqzk1cgnlxfc8 | freed umt5xxl.transformer.encoder.block.11.layer.0.SelfAttention.relative_attention_bias\n
2025-10-31  18:14:45.947 | info | ezqzk1cgnlxfc8 | freed umt5xxl.transformer.encoder.block.10.layer.0.SelfAttention.relative_attention_bias\n
2025-10-31  18:14:45.947 | info | ezqzk1cgnlxfc8 | freed umt5xxl.transformer.encoder.block.1.layer.0.SelfAttention.relative_attention_bias\n
2025-10-31  18:14:45.946 | info | ezqzk1cgnlxfc8 | freed umt5xxl.transformer.encoder.block.0.layer.0.SelfAttention.relative_attention_bias\n
2025-10-31  18:14:45.946 | info | ezqzk1cgnlxfc8 | Unloading WanTEModel\n
2025-10-31  18:14:45.841 | info | ezqzk1cgnlxfc8 | Requested to load WanVAE\n
2025-10-31  18:14:43.897 | info | ezqzk1cgnlxfc8 | lowvram: loaded module regularly umt5xxl.transformer.encoder.block.1.layer.0.SelfAttention.q Linear(in_features=4096, out_features=4096, bias=False)\n
2025-10-31  18:14:43.897 | info | ezqzk1cgnlxfc8 | lowvram: loaded module regularly umt5xxl.transformer.encoder.block.1.layer.0.SelfAttention.v Linear(in_features=4096, out_features=4096, bias=False)\n
2025-10-31  18:14:43.897 | info | ezqzk1cgnlxfc8 | lowvram: loaded module regularly umt5xxl.transformer.encoder.block.10.layer.0.SelfAttention.k Linear(in_features=4096, out_features=4096, bias=False)\n
2025-10-31  18:14:43.897 | info | ezqzk1cgnlxfc8 | lowvram: loaded module regularly umt5xxl.transformer.encoder.block.10.layer.0.SelfAttention.o Linear(in_features=4096, out_features=4096, bias=False)\n
2025-10-31  18:14:43.897 | info | ezqzk1cgnlxfc8 | lowvram: loaded module regularly umt5xxl.transformer.encoder.block.10.layer.0.SelfAttention.q Linear(in_features=4096, out_features=4096, bias=False)\n
2025-10-31  18:14:43.897 | info | ezqzk1cgnlxfc8 | lowvram: loaded module regularly umt5xxl.transformer.encoder.block.10.layer.0.SelfAttention.v Linear(in_features=4096, out_features=4096, bias=False)\n
2025-10-31  18:14:43.897 | info | ezqzk1cgnlxfc8 | lowvram: loaded module regularly umt5xxl.transformer.encoder.block.11.layer.0.SelfAttention.k Linear(in_features=4096, out_features=4096, bias=False)\n
2025-10-31  18:14:43.896 | info | ezqzk1cgnlxfc8 | lowvram: loaded module regularly umt5xxl.transformer.encoder.block.11.layer.0.SelfAttention.o Linear(in_features=4096, out_features=4096, bias=False)\n
2025-10-31  18:14:43.896 | info | ezqzk1cgnlxfc8 | lowvram: loaded module regularly umt5xxl.transformer.encoder.block.11.layer.0.SelfAttention.q Linear(in_features=4096, out_features=4096, bias=False)\n
2025-10-31  18:14:43.896 | info | ezqzk1cgnlxfc8 | lowvram: loaded module regularly umt5xxl.transformer.encoder.block.11.layer.0.SelfAttention.v Linear(in_features=4096, out_features=4096, bias=False)\n
2025-10-31  18:14:43.896 | info | ezqzk1cgnlxfc8 | lowvram: loaded module regularly umt5xxl.transformer.encoder.block.12.layer.0.SelfAttention.k Linear(in_features=4096, out_features=4096, bias=False)\n
2025-10-31  18:14:43.896 | info | ezqzk1cgnlxfc8 | lowvram: loaded module regularly umt5xxl.transformer.encoder.block.12.layer.0.SelfAttention.o Linear(in_features=4096, out_features=4096, bias=False)\n
2025-10-31  18:14:43.896 | info | ezqzk1cgnlxfc8 | lowvram: loaded module regularly umt5xxl.transformer.encoder.block.12.layer.0.SelfAttention.q Linear(in_features=4096, out_features=4096, bias=False)\n
2025-10-31  18:14:43.896 | info | ezqzk1cgnlxfc8 | lowvram: loaded module regularly umt5xxl.transformer.encoder.block.12.layer.0.SelfAttention.v Linear(in_features=4096, out_features=4096, bias=False)\n
2025-10-31  18:14:43.896 | info | ezqzk1cgnlxfc8 | lowvram: loaded module regularly umt5xxl.transformer.encoder.block.13.layer.0.SelfAttention.k Linear(in_features=4096, out_features=4096, bias=False)\n
2025-10-31  18:14:43.896 | info | ezqzk1cgnlxfc8 | lowvram: loaded module regularly umt5xxl.transformer.encoder.block.13.layer.0.SelfAttention.o Linear(in_features=4096, out_features=4096, bias=False)\n
2025-10-31  18:14:43.896 | info | ezqzk1cgnlxfc8 | lowvram: loaded module regularly umt5xxl.transformer.encoder.block.13.layer.0.SelfAttention.q Linear(in_features=4096, out_features=4096, bias=False)\n
2025-10-31  18:14:43.896 | info | ezqzk1cgnlxfc8 | lowvram: loaded module regularly umt5xxl.transformer.encoder.block.13.layer.0.SelfAttention.v Linear(in_features=4096, out_features=4096, bias=False)\n
2025-10-31  18:14:43.896 | info | ezqzk1cgnlxfc8 | lowvram: loaded module regularly umt5xxl.transformer.encoder.block.14.layer.0.SelfAttention.k Linear(in_features=4096, out_features=4096, bias=False)\n
2025-10-31  18:14:43.896 | info | ezqzk1cgnlxfc8 | lowvram: loaded module regularly umt5xxl.transformer.encoder.block.14.layer.0.SelfAttention.o Linear(in_features=4096, out_features=4096, bias=False)\n
2025-10-31  18:14:43.896 | info | ezqzk1cgnlxfc8 | lowvram: loaded module regularly umt5xxl.transformer.encoder.block.14.layer.0.SelfAttention.q Linear(in_features=4096, out_features=4096, bias=False)\n
2025-10-31  18:14:43.896 | info | ezqzk1cgnlxfc8 | lowvram: loaded module regularly umt5xxl.transformer.encoder.block.14.layer.0.SelfAttention.v Linear(in_features=4096, out_features=4096, bias=False)\n
2025-10-31  18:14:43.896 | info | ezqzk1cgnlxfc8 | lowvram: loaded module regularly umt5xxl.transformer.encoder.block.15.layer.0.SelfAttention.k Linear(in_features=4096, out_features=4096, bias=False)\n
2025-10-31  18:14:43.896 | info | ezqzk1cgnlxfc8 | lowvram: loaded module regularly umt5xxl.transformer.encoder.block.15.layer.0.SelfAttention.o Linear(in_features=4096, out_features=4096, bias=False)\n
2025-10-31  18:14:43.896 | info | ezqzk1cgnlxfc8 | lowvram: loaded module regularly umt5xxl.transformer.encoder.block.15.layer.0.SelfAttention.q Linear(in_features=4096, out_features=4096, bias=False)\n
2025-10-31  18:14:43.896 | info | ezqzk1cgnlxfc8 | lowvram: loaded module regularly umt5xxl.transformer.encoder.block.15.layer.0.SelfAttention.v Linear(in_features=4096, out_features=4096, bias=False)\n
2025-10-31  18:14:43.896 | info | ezqzk1cgnlxfc8 | lowvram: loaded module regularly umt5xxl.transformer.encoder.block.16.layer.0.SelfAttention.k Linear(in_features=4096, out_features=4096, bias=False)\n
2025-10-31  18:14:43.896 | info | ezqzk1cgnlxfc8 | lowvram: loaded module regularly umt5xxl.transformer.encoder.block.16.layer.0.SelfAttention.o Linear(in_features=4096, out_features=4096, bias=False)\n
2025-10-31  18:14:43.896 | info | ezqzk1cgnlxfc8 | lowvram: loaded module regularly umt5xxl.transformer.encoder.block.16.layer.0.SelfAttention.q Linear(in_features=4096, out_features=4096, bias=False)\n
2025-10-31  18:14:43.896 | info | ezqzk1cgnlxfc8 | lowvram: loaded module regularly umt5xxl.transformer.encoder.block.16.layer.0.SelfAttention.v Linear(in_features=4096, out_features=4096, bias=False)\n
2025-10-31  18:14:43.896 | info | ezqzk1cgnlxfc8 | lowvram: loaded module regularly umt5xxl.transformer.encoder.block.17.layer.0.SelfAttention.k Linear(in_features=4096, out_features=4096, bias=False)\n
2025-10-31  18:14:43.896 | info | ezqzk1cgnlxfc8 | lowvram: loaded module regularly umt5xxl.transformer.encoder.block.17.layer.0.SelfAttention.o Linear(in_features=4096, out_features=4096, bias=False)\n
2025-10-31  18:14:43.896 | info | ezqzk1cgnlxfc8 | lowvram: loaded module regularly umt5xxl.transformer.encoder.block.17.layer.0.SelfAttention.q Linear(in_features=4096, out_features=4096, bias=False)\n
2025-10-31  18:14:43.896 | info | ezqzk1cgnlxfc8 | lowvram: loaded module regularly umt5xxl.transformer.encoder.block.17.layer.0.SelfAttention.v Linear(in_features=4096, out_features=4096, bias=False)\n
2025-10-31  18:14:43.896 | info | ezqzk1cgnlxfc8 | lowvram: loaded module regularly umt5xxl.transformer.encoder.block.18.layer.0.SelfAttention.k Linear(in_features=4096, out_features=4096, bias=False)\n
2025-10-31  18:14:43.896 | info | ezqzk1cgnlxfc8 | lowvram: loaded module regularly umt5xxl.transformer.encoder.block.18.layer.0.SelfAttention.o Linear(in_features=4096, out_features=4096, bias=False)\n
2025-10-31  18:14:43.896 | info | ezqzk1cgnlxfc8 | lowvram: loaded module regularly umt5xxl.transformer.encoder.block.18.layer.0.SelfAttention.q Linear(in_features=4096, out_features=4096, bias=False)\n
2025-10-31  18:14:43.896 | info | ezqzk1cgnlxfc8 | lowvram: loaded module regularly umt5xxl.transformer.encoder.block.18.layer.0.SelfAttention.v Linear(in_features=4096, out_features=4096, bias=False)\n
2025-10-31  18:14:43.896 | info | ezqzk1cgnlxfc8 | lowvram: loaded module regularly umt5xxl.transformer.encoder.block.19.layer.0.SelfAttention.k Linear(in_features=4096, out_features=4096, bias=False)\n
2025-10-31  18:14:43.896 | info | ezqzk1cgnlxfc8 | lowvram: loaded module regularly umt5xxl.transformer.encoder.block.19.layer.0.SelfAttention.o Linear(in_features=4096, out_features=4096, bias=False)\n
2025-10-31  18:14:43.896 | info | ezqzk1cgnlxfc8 | lowvram: loaded module regularly umt5xxl.transformer.encoder.block.19.layer.0.SelfAttention.q Linear(in_features=4096, out_features=4096, bias=False)\n
2025-10-31  18:14:43.896 | info | ezqzk1cgnlxfc8 | lowvram: loaded module regularly umt5xxl.transformer.encoder.block.19.layer.0.SelfAttention.v Linear(in_features=4096, out_features=4096, bias=False)\n
2025-10-31  18:14:43.896 | info | ezqzk1cgnlxfc8 | lowvram: loaded module regularly umt5xxl.transformer.encoder.block.2.layer.0.SelfAttention.k Linear(in_features=4096, out_features=4096, bias=False)\n
2025-10-31  18:14:43.896 | info | ezqzk1cgnlxfc8 | lowvram: loaded module regularly umt5xxl.transformer.encoder.block.2.layer.0.SelfAttention.o Linear(in_features=4096, out_features=4096, bias=False)\n
2025-10-31  18:14:43.895 | info | ezqzk1cgnlxfc8 | lowvram: loaded module regularly umt5xxl.transformer.encoder.block.2.layer.0.SelfAttention.q Linear(in_features=4096, out_features=4096, bias=False)\n
2025-10-31  18:14:43.895 | info | ezqzk1cgnlxfc8 | lowvram: loaded module regularly umt5xxl.transformer.encoder.block.2.layer.0.SelfAttention.v Linear(in_features=4096, out_features=4096, bias=False)\n
2025-10-31  18:14:43.895 | info | ezqzk1cgnlxfc8 | lowvram: loaded module regularly umt5xxl.transformer.encoder.block.20.layer.0.SelfAttention.k Linear(in_features=4096, out_features=4096, bias=False)\n
2025-10-31  18:14:43.895 | info | ezqzk1cgnlxfc8 | lowvram: loaded module regularly umt5xxl.transformer.encoder.block.20.layer.0.SelfAttention.o Linear(in_features=4096, out_features=4096, bias=False)\n
2025-10-31  18:14:43.895 | info | ezqzk1cgnlxfc8 | lowvram: loaded module regularly umt5xxl.transformer.encoder.block.20.layer.0.SelfAttention.q Linear(in_features=4096, out_features=4096, bias=False)\n
2025-10-31  18:14:43.895 | info | ezqzk1cgnlxfc8 | lowvram: loaded module regularly umt5xxl.transformer.encoder.block.20.layer.0.SelfAttention.v Linear(in_features=4096, out_features=4096, bias=False)\n
2025-10-31  18:14:43.895 | info | ezqzk1cgnlxfc8 | lowvram: loaded module regularly umt5xxl.transformer.encoder.block.21.layer.0.SelfAttention.k Linear(in_features=4096, out_features=4096, bias=False)\n
2025-10-31  18:14:43.895 | info | ezqzk1cgnlxfc8 | lowvram: loaded module regularly umt5xxl.transformer.encoder.block.21.layer.0.SelfAttention.o Linear(in_features=4096, out_features=4096, bias=False)\n
2025-10-31  18:14:43.895 | info | ezqzk1cgnlxfc8 | lowvram: loaded module regularly umt5xxl.transformer.encoder.block.21.layer.0.SelfAttention.q Linear(in_features=4096, out_features=4096, bias=False)\n
2025-10-31  18:14:43.895 | info | ezqzk1cgnlxfc8 | lowvram: loaded module regularly umt5xxl.transformer.encoder.block.21.layer.0.SelfAttention.v Linear(in_features=4096, out_features=4096, bias=False)\n
2025-10-31  18:14:43.895 | info | ezqzk1cgnlxfc8 | lowvram: loaded module regularly umt5xxl.transformer.encoder.block.22.layer.0.SelfAttention.k Linear(in_features=4096, out_features=4096, bias=False)\n
2025-10-31  18:14:43.895 | info | ezqzk1cgnlxfc8 | lowvram: loaded module regularly umt5xxl.transformer.encoder.block.22.layer.0.SelfAttention.o Linear(in_features=4096, out_features=4096, bias=False)\n
2025-10-31  18:14:43.895 | info | ezqzk1cgnlxfc8 | lowvram: loaded module regularly umt5xxl.transformer.encoder.block.22.layer.0.SelfAttention.q Linear(in_features=4096, out_features=4096, bias=False)\n
2025-10-31  18:14:43.895 | info | ezqzk1cgnlxfc8 | lowvram: loaded module regularly umt5xxl.transformer.encoder.block.22.layer.0.SelfAttention.v Linear(in_features=4096, out_features=4096, bias=False)\n
2025-10-31  18:14:43.895 | info | ezqzk1cgnlxfc8 | lowvram: loaded module regularly umt5xxl.transformer.encoder.block.23.layer.0.SelfAttention.k Linear(in_features=4096, out_features=4096, bias=False)\n
2025-10-31  18:14:43.895 | info | ezqzk1cgnlxfc8 | lowvram: loaded module regularly umt5xxl.transformer.encoder.block.23.layer.0.SelfAttention.o Linear(in_features=4096, out_features=4096, bias=False)\n
2025-10-31  18:14:43.895 | info | ezqzk1cgnlxfc8 | lowvram: loaded module regularly umt5xxl.transformer.encoder.block.23.layer.0.SelfAttention.q Linear(in_features=4096, out_features=4096, bias=False)\n
2025-10-31  18:14:43.895 | info | ezqzk1cgnlxfc8 | lowvram: loaded module regularly umt5xxl.transformer.encoder.block.23.layer.0.SelfAttention.v Linear(in_features=4096, out_features=4096, bias=False)\n
2025-10-31  18:14:43.895 | info | ezqzk1cgnlxfc8 | lowvram: loaded module regularly umt5xxl.transformer.encoder.block.3.layer.0.SelfAttention.k Linear(in_features=4096, out_features=4096, bias=False)\n
2025-10-31  18:14:43.895 | info | ezqzk1cgnlxfc8 | lowvram: loaded module regularly umt5xxl.transformer.encoder.block.3.layer.0.SelfAttention.o Linear(in_features=4096, out_features=4096, bias=False)\n
2025-10-31  18:14:43.895 | info | ezqzk1cgnlxfc8 | lowvram: loaded module regularly umt5xxl.transformer.encoder.block.3.layer.0.SelfAttention.q Linear(in_features=4096, out_features=4096, bias=False)\n
2025-10-31  18:14:43.895 | info | ezqzk1cgnlxfc8 | lowvram: loaded module regularly umt5xxl.transformer.encoder.block.3.layer.0.SelfAttention.v Linear(in_features=4096, out_features=4096, bias=False)\n
2025-10-31  18:14:43.895 | info | ezqzk1cgnlxfc8 | lowvram: loaded module regularly umt5xxl.transformer.encoder.block.4.layer.0.SelfAttention.k Linear(in_features=4096, out_features=4096, bias=False)\n
2025-10-31  18:14:43.895 | info | ezqzk1cgnlxfc8 | lowvram: loaded module regularly umt5xxl.transformer.encoder.block.4.layer.0.SelfAttention.o Linear(in_features=4096, out_features=4096, bias=False)\n
2025-10-31  18:14:43.895 | info | ezqzk1cgnlxfc8 | lowvram: loaded module regularly umt5xxl.transformer.encoder.block.4.layer.0.SelfAttention.q Linear(in_features=4096, out_features=4096, bias=False)\n
2025-10-31  18:14:43.895 | info | ezqzk1cgnlxfc8 | lowvram: loaded module regularly umt5xxl.transformer.encoder.block.4.layer.0.SelfAttention.v Linear(in_features=4096, out_features=4096, bias=False)\n
2025-10-31  18:14:43.895 | info | ezqzk1cgnlxfc8 | lowvram: loaded module regularly umt5xxl.transformer.encoder.block.5.layer.0.SelfAttention.k Linear(in_features=4096, out_features=4096, bias=False)\n
2025-10-31  18:14:43.895 | info | ezqzk1cgnlxfc8 | lowvram: loaded module regularly umt5xxl.transformer.encoder.block.5.layer.0.SelfAttention.o Linear(in_features=4096, out_features=4096, bias=False)\n
2025-10-31  18:14:43.895 | info | ezqzk1cgnlxfc8 | lowvram: loaded module regularly umt5xxl.transformer.encoder.block.5.layer.0.SelfAttention.q Linear(in_features=4096, out_features=4096, bias=False)\n
2025-10-31  18:14:43.895 | info | ezqzk1cgnlxfc8 | lowvram: loaded module regularly umt5xxl.transformer.encoder.block.5.layer.0.SelfAttention.v Linear(in_features=4096, out_features=4096, bias=False)\n
2025-10-31  18:14:43.895 | info | ezqzk1cgnlxfc8 | lowvram: loaded module regularly umt5xxl.transformer.encoder.block.6.layer.0.SelfAttention.k Linear(in_features=4096, out_features=4096, bias=False)\n
2025-10-31  18:14:43.895 | info | ezqzk1cgnlxfc8 | lowvram: loaded module regularly umt5xxl.transformer.encoder.block.6.layer.0.SelfAttention.o Linear(in_features=4096, out_features=4096, bias=False)\n
2025-10-31  18:14:43.895 | info | ezqzk1cgnlxfc8 | lowvram: loaded module regularly umt5xxl.transformer.encoder.block.6.layer.0.SelfAttention.q Linear(in_features=4096, out_features=4096, bias=False)\n
2025-10-31  18:14:43.895 | info | ezqzk1cgnlxfc8 | lowvram: loaded module regularly umt5xxl.transformer.encoder.block.6.layer.0.SelfAttention.v Linear(in_features=4096, out_features=4096, bias=False)\n
2025-10-31  18:14:43.895 | info | ezqzk1cgnlxfc8 | lowvram: loaded module regularly umt5xxl.transformer.encoder.block.7.layer.0.SelfAttention.k Linear(in_features=4096, out_features=4096, bias=False)\n
2025-10-31  18:14:43.895 | info | ezqzk1cgnlxfc8 | lowvram: loaded module regularly umt5xxl.transformer.encoder.block.7.layer.0.SelfAttention.o Linear(in_features=4096, out_features=4096, bias=False)\n
2025-10-31  18:14:43.894 | info | ezqzk1cgnlxfc8 | lowvram: loaded module regularly umt5xxl.transformer.encoder.block.7.layer.0.SelfAttention.q Linear(in_features=4096, out_features=4096, bias=False)\n
2025-10-31  18:14:43.894 | info | ezqzk1cgnlxfc8 | lowvram: loaded module regularly umt5xxl.transformer.encoder.block.7.layer.0.SelfAttention.v Linear(in_features=4096, out_features=4096, bias=False)\n
2025-10-31  18:14:43.894 | info | ezqzk1cgnlxfc8 | lowvram: loaded module regularly umt5xxl.transformer.encoder.block.8.layer.0.SelfAttention.k Linear(in_features=4096, out_features=4096, bias=False)\n
2025-10-31  18:14:43.894 | info | ezqzk1cgnlxfc8 | lowvram: loaded module regularly umt5xxl.transformer.encoder.block.8.layer.0.SelfAttention.o Linear(in_features=4096, out_features=4096, bias=False)\n
2025-10-31  18:14:43.894 | info | ezqzk1cgnlxfc8 | lowvram: loaded module regularly umt5xxl.transformer.encoder.block.8.layer.0.SelfAttention.q Linear(in_features=4096, out_features=4096, bias=False)\n
2025-10-31  18:14:43.894 | info | ezqzk1cgnlxfc8 | lowvram: loaded module regularly umt5xxl.transformer.encoder.block.8.layer.0.SelfAttention.v Linear(in_features=4096, out_features=4096, bias=False)\n
2025-10-31  18:14:43.894 | info | ezqzk1cgnlxfc8 | lowvram: loaded module regularly umt5xxl.transformer.encoder.block.9.layer.0.SelfAttention.k Linear(in_features=4096, out_features=4096, bias=False)\n